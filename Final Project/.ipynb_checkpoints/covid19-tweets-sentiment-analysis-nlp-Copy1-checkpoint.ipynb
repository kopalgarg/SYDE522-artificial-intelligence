{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sF1azMHDC_Q-"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yk2ky07-C_RA"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score,  accuracy_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score,  accuracy_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "D50G4l0SC_RA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7aht-HZC_RB",
    "outputId": "da9b097a-0900-4f8f-b500-c35f03c33381"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWGibQmRC_RB",
    "outputId": "862c812c-d2b5-443c-e35e-dc5daf2fba70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emot in /Users/kgarg/opt/anaconda3/lib/python3.8/site-packages (2.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbOpjZOUKz40",
    "outputId": "355a85bf-91de-46f2-eb9e-3bc5bf3c49be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in /Users/kgarg/opt/anaconda3/lib/python3.8/site-packages (0.6.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9AVjkrtaC_RC"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473506"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OriginalTweet'].str.lower().str.split().apply(len).sum()\n",
    "pd.options.display.max_colwidth=200\n",
    "df['OriginalTweet'][3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KYGb9A4IC_RC"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/Corona_NLP_train.csv', encoding=\"ISO-8859-1\", low_memory=False)\n",
    "test = pd.read_csv('./data/Corona_NLP_test.csv', encoding=\"ISO-8859-1\", low_memory=False) \n",
    "#df = train.append(test, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jw9JFgGgC_RE"
   },
   "outputs": [],
   "source": [
    "# -- filling missing values\n",
    "train['Location'].fillna(value='unknown', inplace=True) \n",
    "test['Location'].fillna(value='unknown', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vE-GHkyGC_RE"
   },
   "outputs": [],
   "source": [
    "# -- label encoding \n",
    "encoding = {'Extremely Negative': 'Negative',\n",
    "            'Extremely Positive': 'Positive'\n",
    "           }\n",
    "labels = ['Negative', 'Positive']\n",
    "train['Sentiment'].replace(encoding, inplace=True)\n",
    "train[\"sentiment\"] = LabelEncoder().fit_transform(train[\"Sentiment\"])\n",
    "\n",
    "test['Sentiment'].replace(encoding, inplace=True)\n",
    "test[\"sentiment\"] = LabelEncoder().fit_transform(test[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3MKNdTFCC_RG"
   },
   "outputs": [],
   "source": [
    "# -- remove URLs\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# -- remove HTML\n",
    "def html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_urls)\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(html)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(remove_urls)\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UXbuAXvlC_RH"
   },
   "outputs": [],
   "source": [
    "# -- lowercase\n",
    "train['OriginalTweet'] = train['OriginalTweet'].str.lower()\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "n3RgoyTKC_RH"
   },
   "outputs": [],
   "source": [
    "# -- convert emojis and emoticons to words\n",
    "def convert_emojis_emoticons(text):\n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(convert_emojis_emoticons)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(convert_emojis_emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qwibfPcyC_RO"
   },
   "outputs": [],
   "source": [
    "# -- remove special and non-ASCII characters\n",
    "def clean(tweet): \n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â²\", \"\", tweet)\n",
    "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â¹\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â½\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â¾\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼berweist\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼cretsiz\", \"\", tweet)\n",
    "    tweet = re.sub(r\"zã¼rich\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼retime\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "    tweet = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'mentioned', tweet)\n",
    "    tweet = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'referance', tweet)\n",
    "    tweet = re.sub(r'£|\\$', 'money', tweet)\n",
    "    tweet = re.sub(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b', ' ', tweet)\n",
    "    tweet = re.sub(r'\\d+(\\.\\d+)?', ' ', tweet) \n",
    "    tweet = re.sub(r'[^\\w\\d\\s]', ' ', tweet)\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    tweet = re.sub(r'^\\s+|\\s+?$', '', tweet.lower())\n",
    "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
    "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
    "    tweet = re.sub(r\"&amp;\", \"&\", tweet) \n",
    "    tweet = re.sub(r\"_\", \"  \", tweet)\n",
    "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
    "    for p in punctuations:\n",
    "        tweet = tweet.replace(p, f' {p} ')\n",
    "    return str(tweet)\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(clean)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "QWAIdXXiX7R3"
   },
   "outputs": [],
   "source": [
    "# -- spellcheck and keep words that are in the English dictionary\n",
    "spell = SpellChecker(distance = 1, language='en')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else: \n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "def ensure_english(text):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(text) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(correct_spellings)\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(ensure_english)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(correct_spellings)\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(ensure_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "th8JB9tjC_RP"
   },
   "outputs": [],
   "source": [
    "# -- remove punctuation\n",
    "import string\n",
    "regular_punct = list(string.punctuation)\n",
    "def remove_punctuation(text):\n",
    "    for punc in regular_punct:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, ' ')\n",
    "    return text.strip()\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_punctuation)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- remove stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "def remove_stopwords(tweet):\n",
    "  tweet = tweet.split()\n",
    "  tweet = \" \".join([word for word in tweet if not word in en_stops])  \n",
    "  return tweet\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_stopwords)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "H1ts6loeC_RT"
   },
   "outputs": [],
   "source": [
    "# -- tokenize\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(word_tokenize)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IJ6iapoCC_RU"
   },
   "outputs": [],
   "source": [
    "# -- lematize\n",
    "lem = WordNetLemmatizer()\n",
    "def lemma_wordnet(input):\n",
    "    return [lem.lemmatize(w) for w in input]\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(lemma_wordnet)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(lemma_wordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XKrQG5dAC_RU"
   },
   "outputs": [],
   "source": [
    "# -- combine individual words\n",
    "def combine_text(input):\n",
    "    combined = ' '.join(input)\n",
    "    return combined\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(combine_text)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(combine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "v48ujX1fC_RV"
   },
   "outputs": [],
   "source": [
    "# -- Bag of words\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1, 1))\n",
    "X_train_bow = cv.fit_transform(train['OriginalTweet']) \n",
    "Y_train_bow = train['sentiment'] \n",
    "\n",
    "X_test_bow = cv.transform(test['OriginalTweet'])\n",
    "Y_test_bow = test['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Bag of words - bigrams\n",
    "\n",
    "cv_bbow = CountVectorizer(ngram_range=(2, 2))\n",
    "X_train_bbow = cv_bbow.fit_transform(train['OriginalTweet']) \n",
    "Y_train_bbow = train['sentiment']\n",
    "\n",
    "X_test_bbow = cv_bbow.transform(test['OriginalTweet']) \n",
    "Y_test_bbow = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TF-IDF\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 2, max_df = 0.8, use_idf = True, ngram_range=(1, 1))\n",
    "\n",
    "vectorizer.fit(train)\n",
    "X_train_tfidf = vectorizer.fit_transform(train['OriginalTweet'])\n",
    "Y_train_tfidf = train['sentiment'] \n",
    "\n",
    "X_test_tfidf =vectorizer.transform(test['OriginalTweet']) \n",
    "Y_test_tfidf = test['sentiment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "8NYhp501C_RV",
    "outputId": "c80277c1-6b9f-4bf4-baeb-9200a618e2c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-BoW:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(41157, 387999)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa baker</th>\n",
       "      <th>aa cristobal</th>\n",
       "      <th>aaa covid</th>\n",
       "      <th>aaa gas</th>\n",
       "      <th>aaa low</th>\n",
       "      <th>aaa official</th>\n",
       "      <th>aaa say</th>\n",
       "      <th>aaa texas</th>\n",
       "      <th>aaaaas commission</th>\n",
       "      <th>aaaand toilet</th>\n",
       "      <th>...</th>\n",
       "      <th>âmoney worth</th>\n",
       "      <th>âmoney would</th>\n",
       "      <th>âmoney wow</th>\n",
       "      <th>âmoney yes</th>\n",
       "      <th>âmoney yorkshire</th>\n",
       "      <th>âmoney âmoney</th>\n",
       "      <th>âmoneycashtag chance</th>\n",
       "      <th>âmoneyxx offer</th>\n",
       "      <th>ãmoneyo contra</th>\n",
       "      <th>ãmoneyo precaucao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 387999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa baker  aa cristobal  aaa covid  aaa gas  aaa low  aaa official  aaa say  \\\n",
       "0         0             0          0        0        0             0        0   \n",
       "1         0             0          0        0        0             0        0   \n",
       "2         0             0          0        0        0             0        0   \n",
       "3         0             0          0        0        0             0        0   \n",
       "4         0             0          0        0        0             0        0   \n",
       "\n",
       "   aaa texas  aaaaas commission  aaaand toilet  ...  âmoney worth  \\\n",
       "0          0                  0              0  ...             0   \n",
       "1          0                  0              0  ...             0   \n",
       "2          0                  0              0  ...             0   \n",
       "3          0                  0              0  ...             0   \n",
       "4          0                  0              0  ...             0   \n",
       "\n",
       "   âmoney would  âmoney wow  âmoney yes  âmoney yorkshire  âmoney âmoney  \\\n",
       "0             0           0           0                 0              0   \n",
       "1             0           0           0                 0              0   \n",
       "2             0           0           0                 0              0   \n",
       "3             0           0           0                 0              0   \n",
       "4             0           0           0                 0              0   \n",
       "\n",
       "   âmoneycashtag chance  âmoneyxx offer  ãmoneyo contra  ãmoneyo precaucao  \n",
       "0                     0               0               0                  0  \n",
       "1                     0               0               0                  0  \n",
       "2                     0               0               0                  0  \n",
       "3                     0               0               0                  0  \n",
       "4                     0               0               0                  0  \n",
       "\n",
       "[5 rows x 387999 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"B-BoW:\", X_train_bbow.shape)\n",
    "df_bbow = pd.DataFrame(X_train_bbow.toarray(), columns=cv_bbow.get_feature_names())\n",
    "display(df_bbow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.65755588 0.64856657 0.64390718 0.64050541 0.63868303]\n",
      "0.6458436126242504\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.65767736 0.64880952 0.64402867 0.64086988 0.63941198]\n",
      "0.6461594827632009\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.67237609 0.66399417 0.66128052 0.66200948 0.66128052]\n",
      "0.6641881576901374\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.67589893 0.66873178 0.66735512 0.67209331 0.67099988]\n",
      "0.6710158029228666\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.66800292 0.66265792 0.6586077  0.66516827 0.67014944]\n",
      "0.6649172479447026\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.64917396 0.64856657 0.6420848  0.65058924 0.65447698]\n",
      "0.6489783078477759\n",
      "\n",
      "\n",
      "0.6671932596103213\n",
      "precision: [0.74764595 0.60606061 0.60911602]\n",
      "recall: [0.72933252 0.03231018 0.85575679]\n",
      "fscore: [0.7383757  0.06134969 0.71167294]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with bag of word\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_bow, Y_train_bow, cv=5)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "\n",
    "mnb = MultinomialNB(alpha = 1)\n",
    "mnb.fit(X_train_bow, Y_train_bow)\n",
    "print(mnb.score(X_test_bow, Y_test_bow))\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_bow, mnb.predict(X_test_bow))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "z7c9aFuVC_RW",
    "outputId": "509a7016-9525-4449-af87-8e97ac9e9266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.55272109 0.56632653 0.53814383 0.55199223 0.55417881 0.5617104\n",
      " 0.53911565 0.55674362 0.5671932  0.55893074]\n",
      "0.5547056090271554\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.53790087 0.54591837 0.52380952 0.53328474 0.53206997 0.54081633\n",
      " 0.51797862 0.5399757  0.54313487 0.53341434]\n",
      "0.5348303334525963\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.44047619 0.42614189 0.43634597 0.43707483 0.4154519  0.42031098\n",
      " 0.40913508 0.41652491 0.41919806 0.40413123]\n",
      "0.4224791023856166\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.54446064 0.52988338 0.53279883 0.53401361 0.51627794 0.53911565\n",
      " 0.51044704 0.52466586 0.51980559 0.51154313]\n",
      "0.5263011665350048\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.57798834 0.55344995 0.55442177 0.56073858 0.5451895  0.57458698\n",
      " 0.55272109 0.5582017  0.55893074 0.54556501]\n",
      "0.5581793658272196\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.57555879 0.56997085 0.5675413  0.58114674 0.55466472 0.58041788\n",
      " 0.57677357 0.57181045 0.5837181  0.56840826]\n",
      "0.5730010674639583\n",
      "\n",
      "\n",
      "0.5668773038441285\n",
      "precision: [0.65932452 0.46153846 0.51547668]\n",
      "recall: [0.54990814 0.00969305 0.80789133]\n",
      "fscore: [0.59966611 0.01898734 0.62937768]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with bigram bag of word\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_bbow, Y_train_bbow, cv=10)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "\n",
    "mnb.fit(X_train_bbow, Y_train_bbow)\n",
    "print(mnb.score(X_test_bbow, Y_test_bbow))\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_bbow, mnb.predict(X_test_bbow))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "#accuracy_score(mnb.predict(X_test_bbow), Y_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "C4B0It9ZC_RW",
    "outputId": "bc355275-2945-49b7-bb14-a470f33c7569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  175.0\n",
      "[0.47667638 0.48785228 0.48420797 0.4749757  0.47400389 0.46622935\n",
      " 0.47570457 0.46950182 0.45686513 0.45929526]\n",
      "0.47253123571942224\n",
      "\n",
      "\n",
      "alpha:  200.0\n",
      "[0.47060253 0.48080661 0.47594752 0.47011662 0.46817298 0.46015549\n",
      " 0.46817298 0.46196841 0.45224787 0.45735115]\n",
      "0.4665542168959235\n",
      "\n",
      "\n",
      "alpha:  225.0\n",
      "[0.46501458 0.47400389 0.47084548 0.4664723  0.46282799 0.45699708\n",
      " 0.46282799 0.4563791  0.44860267 0.45516403]\n",
      "0.4619135118029159\n",
      "\n",
      "\n",
      "alpha:  250.0\n",
      "[0.4606414  0.46987366 0.46525753 0.46379981 0.45845481 0.45359572\n",
      " 0.45894072 0.45224787 0.44738761 0.45176185]\n",
      "0.45819609808860184\n",
      "\n",
      "\n",
      "alpha:  300.0\n",
      "[0.4552964  0.45845481 0.45748299 0.4579689  0.45408163 0.45019436\n",
      " 0.45189504 0.44617254 0.44398542 0.44690158]\n",
      "0.4522433687934469\n",
      "\n",
      "\n",
      "0.6542917324907846\n",
      "precision: [0.74020888 0.73333333 0.59342638]\n",
      "recall: [0.69442743 0.05331179 0.85252264]\n",
      "fscore: [0.71658768 0.09939759 0.69976108]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with TF-IDF\n",
    "alpha = [175.0, 200.0, 225.0, 250.0, 300.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_tfidf, Y_train_tfidf, cv=10)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, Y_train_tfidf)\n",
    "print(mnb.score(X_test_tfidf, Y_test_tfidf))\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_tfidf, mnb.predict(X_test_tfidf))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "p0O4c1bVC_RZ"
   },
   "outputs": [],
   "source": [
    "# -- decision tree classifier with BoW\n",
    "dtclassifier=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None)\n",
    "score=cross_val_score(dtclassifier, X_train_bow, Y_train_bow, cv=10)\n",
    "dtclassifier.fit(X_train_bow, Y_train_bow)\n",
    "preddt = dtclassifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_para = {'criterion':['gini','entropy']}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=None), tree_para, cv=10)\n",
    "clf.fit(X_train_bow, Y_train_bow)\n",
    "preddt = dtclassifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "O6sZIkRCC_RZ",
    "outputId": "d7a6c598-e06c-4d6f-d694-17af5d0c26c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6545550289626119\n",
      "precision: [0.68603043 0.55375552 0.66826061]\n",
      "recall: [0.60747091 0.60743134 0.72315653]\n",
      "fscore: [0.64436505 0.57935285 0.69462566]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_bow)\n",
    "print(accuracy)\n",
    "#print(score.mean())\n",
    "# unigram: .69\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_bbow, preddt)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- decision tree classifier with B-BoW\n",
    "tree_para = {'criterion':['gini','entropy']}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=None), tree_para, cv=10)\n",
    "clf.fit(X_train_bbow, Y_train_bbow)\n",
    "preddt = clf.predict(X_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_bbow)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_bbow, preddt)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "K2t4tRpGC_Ra"
   },
   "outputs": [],
   "source": [
    "# -- decision tree classifier with tf-idf\n",
    "tree_para = {'criterion':['gini','entropy']}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=None), tree_para, cv=10)\n",
    "clf.fit(X_train_tfidf,Y_train_tfidf)\n",
    "preddt = clf.predict(X_test_tfidf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "6ecSbdERC_Ra",
    "outputId": "cd48ef80-cf60-4b51-d19f-e32eb15f514d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5958399157451291\n",
      "precision: [0.63685272 0.4435591  0.63029525]\n",
      "recall: [0.57991427 0.53957997 0.63518758]\n",
      "fscore: [0.60705128 0.48688047 0.63273196]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_tfidf)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_tfidf, preddt)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "3SQdF6eqC_Rb",
    "outputId": "f4e9fdda-9853-4141-fb94-3099fc06f3d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVC(kernel=linear)\n",
      "Training time: 1458.265711s; Prediction time: 12.310515s\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3d8f0483a0f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time: %fs; Prediction time: %fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_linear_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_linear_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positive: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negative: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'notr: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Neutral'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Positive'"
     ]
    }
   ],
   "source": [
    "# -- SVM, kernel=linear - BoW\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(X_train_bow, Y_train_bow)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(X_test_bow)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "# results\n",
    "print(\"Results for SVC(kernel=linear)\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7943654555028963\n",
      "precision: [0.8140263  0.67633588 0.8240621 ]\n",
      "recall: [0.79608083 0.71567044 0.8240621 ]\n",
      "fscore: [0.80495356 0.69544741 0.8240621 ]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(prediction_linear,Y_test_bow)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_bow, prediction_linear)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "6k6epXw-C_Rb",
    "outputId": "0e283bf4-085d-40da-d89d-544064f67b7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -- logistic regression with bow \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class=\"multinomial\")\n",
    "log_reg.fit(X_train_bow, Y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3SKYyCzjC_Rc",
    "outputId": "6c3fab93-a275-427f-e550-428fecad07e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8022643496577145"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = log_reg.score(X_test_bow, Y_test_bow)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "fVDYoV1DC_Rc",
    "outputId": "afd36e64-3249-4fed-ba18-bc1c7e8de377"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_values</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.596893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.726172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.786203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.802264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.784623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.769879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.771195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_values  Test Accuracy\n",
       "0     0.001       0.596893\n",
       "1     0.010       0.726172\n",
       "2     0.100       0.786203\n",
       "3     1.000       0.802264\n",
       "4    10.000       0.784623\n",
       "5   100.000       0.769879\n",
       "6  1000.000       0.771195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- validation for multinomial log reg \n",
    "C_values = [0.001,0.01, 0.1,1,10,100, 1000]\n",
    "\n",
    "accuracy_values = pd.DataFrame(columns=['C_values', 'Test Accuracy'])\n",
    "\n",
    "for c in C_values:\n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(penalty = 'l2', C = c, random_state = 0, solver='lbfgs', multi_class='multinomial')\n",
    "    lr.fit(X_train_bow, Y_train_bow)\n",
    "    accuracy_values = accuracy_values.append({'C_values': c,\n",
    "                                              'Test Accuracy': lr.score(X_test_bow, Y_test_bow)\n",
    "                                             }, ignore_index=True)\n",
    "display(accuracy_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "sJbMApy1C_Rc"
   },
   "outputs": [],
   "source": [
    "# -- grid search\n",
    "parameters = {\"C\": [10 ** x for x in range (-5, 5, 1)],\n",
    "              \"penalty\": ['l1', 'l2']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "plzyULwvC_Rc",
    "outputId": "39121d6c-46ca-4aeb-c2a5-23264363b5b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(multi_class='multinomial'),\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000, 10000],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_cv = GridSearchCV(estimator=log_reg,\n",
    "                       param_grid = parameters,\n",
    "                       cv = 10\n",
    "                      )\n",
    "\n",
    "grid_cv.fit(X_train_bow, Y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "vvYh6Su_C_Rd",
    "outputId": "e3657790-b054-46ec-8b5c-3ee8c62c9969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters :  {'C': 1, 'penalty': 'l2'}\n",
      "Best Score      :  0.8028285433249849\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters : \", grid_cv.best_params_)\n",
    "print(\"Best Score      : \", grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDnHvC_AC_Rd",
    "outputId": "f8289337-6d4d-4f38-a56a-74322e3f0866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 11.2 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.313961</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l2'}</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437152</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.190604</td>\n",
       "      <td>0.081269</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437152</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.347032</td>\n",
       "      <td>0.042141</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.438019</td>\n",
       "      <td>0.439798</td>\n",
       "      <td>0.438909</td>\n",
       "      <td>0.438019</td>\n",
       "      <td>0.438909</td>\n",
       "      <td>0.439502</td>\n",
       "      <td>0.439632</td>\n",
       "      <td>0.439929</td>\n",
       "      <td>0.439039</td>\n",
       "      <td>0.439632</td>\n",
       "      <td>0.439139</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.741687</td>\n",
       "      <td>0.069908</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>0.575030</td>\n",
       "      <td>0.559312</td>\n",
       "      <td>0.567023</td>\n",
       "      <td>0.551008</td>\n",
       "      <td>0.570285</td>\n",
       "      <td>0.564947</td>\n",
       "      <td>0.557995</td>\n",
       "      <td>0.563631</td>\n",
       "      <td>0.564818</td>\n",
       "      <td>0.555918</td>\n",
       "      <td>0.562997</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.001108</td>\n",
       "      <td>0.650369</td>\n",
       "      <td>0.011164</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.684164</td>\n",
       "      <td>0.673488</td>\n",
       "      <td>0.678826</td>\n",
       "      <td>0.653025</td>\n",
       "      <td>0.682681</td>\n",
       "      <td>0.668743</td>\n",
       "      <td>0.674281</td>\n",
       "      <td>0.680510</td>\n",
       "      <td>0.673984</td>\n",
       "      <td>0.659745</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38.848168</td>\n",
       "      <td>2.187563</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.784401</td>\n",
       "      <td>0.776394</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.762159</td>\n",
       "      <td>0.784994</td>\n",
       "      <td>0.770463</td>\n",
       "      <td>0.773658</td>\n",
       "      <td>0.775734</td>\n",
       "      <td>0.785227</td>\n",
       "      <td>0.762978</td>\n",
       "      <td>0.774321</td>\n",
       "      <td>0.008267</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>41.995080</td>\n",
       "      <td>0.480354</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.827699</td>\n",
       "      <td>0.814650</td>\n",
       "      <td>0.810202</td>\n",
       "      <td>0.814353</td>\n",
       "      <td>0.826216</td>\n",
       "      <td>0.819098</td>\n",
       "      <td>0.819045</td>\n",
       "      <td>0.815188</td>\n",
       "      <td>0.823791</td>\n",
       "      <td>0.814892</td>\n",
       "      <td>0.818513</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 100, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>41.145590</td>\n",
       "      <td>0.834779</td>\n",
       "      <td>0.013074</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "      <td>0.816726</td>\n",
       "      <td>0.797450</td>\n",
       "      <td>0.803974</td>\n",
       "      <td>0.808126</td>\n",
       "      <td>0.820285</td>\n",
       "      <td>0.811388</td>\n",
       "      <td>0.815485</td>\n",
       "      <td>0.812519</td>\n",
       "      <td>0.819341</td>\n",
       "      <td>0.818155</td>\n",
       "      <td>0.812345</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41.099051</td>\n",
       "      <td>0.950770</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l2'}</td>\n",
       "      <td>0.801601</td>\n",
       "      <td>0.792705</td>\n",
       "      <td>0.797746</td>\n",
       "      <td>0.793298</td>\n",
       "      <td>0.804567</td>\n",
       "      <td>0.801008</td>\n",
       "      <td>0.798576</td>\n",
       "      <td>0.798279</td>\n",
       "      <td>0.803916</td>\n",
       "      <td>0.808662</td>\n",
       "      <td>0.800036</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10000, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40.524569</td>\n",
       "      <td>0.326188</td>\n",
       "      <td>0.011391</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>10000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10000, 'penalty': 'l2'}</td>\n",
       "      <td>0.800119</td>\n",
       "      <td>0.790629</td>\n",
       "      <td>0.793001</td>\n",
       "      <td>0.780546</td>\n",
       "      <td>0.808719</td>\n",
       "      <td>0.793891</td>\n",
       "      <td>0.795313</td>\n",
       "      <td>0.795313</td>\n",
       "      <td>0.797983</td>\n",
       "      <td>0.798576</td>\n",
       "      <td>0.795409</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.002367      0.000275         0.000000        0.000000   1e-05   \n",
       "1        3.313961      0.044434         0.010587        0.000077   1e-05   \n",
       "2        0.002228      0.000192         0.000000        0.000000  0.0001   \n",
       "3        3.190604      0.081269         0.011091        0.001986  0.0001   \n",
       "4        0.002420      0.000151         0.000000        0.000000   0.001   \n",
       "5        3.347032      0.042141         0.011306        0.002212   0.001   \n",
       "6        0.002300      0.000184         0.000000        0.000000    0.01   \n",
       "7        6.741687      0.069908         0.011410        0.002420    0.01   \n",
       "8        0.002367      0.000176         0.000000        0.000000     0.1   \n",
       "9       17.001108      0.650369         0.011164        0.001499     0.1   \n",
       "10       0.002403      0.000193         0.000000        0.000000       1   \n",
       "11      38.848168      2.187563         0.010815        0.000472       1   \n",
       "12       0.002316      0.000240         0.000000        0.000000      10   \n",
       "13      41.995080      0.480354         0.010693        0.000114      10   \n",
       "14       0.002336      0.000187         0.000000        0.000000     100   \n",
       "15      41.145590      0.834779         0.013074        0.007048     100   \n",
       "16       0.002140      0.000289         0.000000        0.000000    1000   \n",
       "17      41.099051      0.950770         0.010516        0.000163    1000   \n",
       "18       0.002234      0.000265         0.000000        0.000000   10000   \n",
       "19      40.524569      0.326188         0.011391        0.002111   10000   \n",
       "\n",
       "   param_penalty                          params  split0_test_score  \\\n",
       "0             l1   {'C': 1e-05, 'penalty': 'l1'}                NaN   \n",
       "1             l2   {'C': 1e-05, 'penalty': 'l2'}           0.437129   \n",
       "2             l1  {'C': 0.0001, 'penalty': 'l1'}                NaN   \n",
       "3             l2  {'C': 0.0001, 'penalty': 'l2'}           0.437129   \n",
       "4             l1   {'C': 0.001, 'penalty': 'l1'}                NaN   \n",
       "5             l2   {'C': 0.001, 'penalty': 'l2'}           0.438019   \n",
       "6             l1    {'C': 0.01, 'penalty': 'l1'}                NaN   \n",
       "7             l2    {'C': 0.01, 'penalty': 'l2'}           0.575030   \n",
       "8             l1     {'C': 0.1, 'penalty': 'l1'}                NaN   \n",
       "9             l2     {'C': 0.1, 'penalty': 'l2'}           0.684164   \n",
       "10            l1       {'C': 1, 'penalty': 'l1'}                NaN   \n",
       "11            l2       {'C': 1, 'penalty': 'l2'}           0.784401   \n",
       "12            l1      {'C': 10, 'penalty': 'l1'}                NaN   \n",
       "13            l2      {'C': 10, 'penalty': 'l2'}           0.827699   \n",
       "14            l1     {'C': 100, 'penalty': 'l1'}                NaN   \n",
       "15            l2     {'C': 100, 'penalty': 'l2'}           0.816726   \n",
       "16            l1    {'C': 1000, 'penalty': 'l1'}                NaN   \n",
       "17            l2    {'C': 1000, 'penalty': 'l2'}           0.801601   \n",
       "18            l1   {'C': 10000, 'penalty': 'l1'}                NaN   \n",
       "19            l2   {'C': 10000, 'penalty': 'l2'}           0.800119   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.436833           0.437129           0.437129   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.436833           0.437129           0.437129   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.439798           0.438909           0.438019   \n",
       "6                 NaN                NaN                NaN   \n",
       "7            0.559312           0.567023           0.551008   \n",
       "8                 NaN                NaN                NaN   \n",
       "9            0.673488           0.678826           0.653025   \n",
       "10                NaN                NaN                NaN   \n",
       "11           0.776394           0.767200           0.762159   \n",
       "12                NaN                NaN                NaN   \n",
       "13           0.814650           0.810202           0.814353   \n",
       "14                NaN                NaN                NaN   \n",
       "15           0.797450           0.803974           0.808126   \n",
       "16                NaN                NaN                NaN   \n",
       "17           0.792705           0.797746           0.793298   \n",
       "18                NaN                NaN                NaN   \n",
       "19           0.790629           0.793001           0.780546   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.437129           0.437129           0.437259   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.437129           0.437129           0.437259   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.438909           0.439502           0.439632   \n",
       "6                 NaN                NaN                NaN   \n",
       "7            0.570285           0.564947           0.557995   \n",
       "8                 NaN                NaN                NaN   \n",
       "9            0.682681           0.668743           0.674281   \n",
       "10                NaN                NaN                NaN   \n",
       "11           0.784994           0.770463           0.773658   \n",
       "12                NaN                NaN                NaN   \n",
       "13           0.826216           0.819098           0.819045   \n",
       "14                NaN                NaN                NaN   \n",
       "15           0.820285           0.811388           0.815485   \n",
       "16                NaN                NaN                NaN   \n",
       "17           0.804567           0.801008           0.798576   \n",
       "18                NaN                NaN                NaN   \n",
       "19           0.808719           0.793891           0.795313   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0                 NaN                NaN                NaN              NaN   \n",
       "1            0.437259           0.437259           0.437259         0.437152   \n",
       "2                 NaN                NaN                NaN              NaN   \n",
       "3            0.437259           0.437259           0.437259         0.437152   \n",
       "4                 NaN                NaN                NaN              NaN   \n",
       "5            0.439929           0.439039           0.439632         0.439139   \n",
       "6                 NaN                NaN                NaN              NaN   \n",
       "7            0.563631           0.564818           0.555918         0.562997   \n",
       "8                 NaN                NaN                NaN              NaN   \n",
       "9            0.680510           0.673984           0.659745         0.672944   \n",
       "10                NaN                NaN                NaN              NaN   \n",
       "11           0.775734           0.785227           0.762978         0.774321   \n",
       "12                NaN                NaN                NaN              NaN   \n",
       "13           0.815188           0.823791           0.814892         0.818513   \n",
       "14                NaN                NaN                NaN              NaN   \n",
       "15           0.812519           0.819341           0.818155         0.812345   \n",
       "16                NaN                NaN                NaN              NaN   \n",
       "17           0.798279           0.803916           0.808662         0.800036   \n",
       "18                NaN                NaN                NaN              NaN   \n",
       "19           0.795313           0.797983           0.798576         0.795409   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0              NaN               20  \n",
       "1         0.000123                9  \n",
       "2              NaN               18  \n",
       "3         0.000123                9  \n",
       "4              NaN               15  \n",
       "5         0.000656                8  \n",
       "6              NaN               11  \n",
       "7         0.006738                7  \n",
       "8              NaN               12  \n",
       "9         0.009510                6  \n",
       "10             NaN               14  \n",
       "11        0.008267                5  \n",
       "12             NaN               16  \n",
       "13        0.005456                1  \n",
       "14             NaN               17  \n",
       "15        0.006968                2  \n",
       "16             NaN               19  \n",
       "17        0.004722                3  \n",
       "18             NaN               13  \n",
       "19        0.006840                4  "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   mean_fit_time      20 non-null     float64\n",
      " 1   std_fit_time       20 non-null     float64\n",
      " 2   mean_score_time    20 non-null     float64\n",
      " 3   std_score_time     20 non-null     float64\n",
      " 4   param_C            20 non-null     object \n",
      " 5   param_penalty      20 non-null     object \n",
      " 6   params             20 non-null     object \n",
      " 7   split0_test_score  10 non-null     float64\n",
      " 8   split1_test_score  10 non-null     float64\n",
      " 9   split2_test_score  10 non-null     float64\n",
      " 10  split3_test_score  10 non-null     float64\n",
      " 11  split4_test_score  10 non-null     float64\n",
      " 12  split5_test_score  10 non-null     float64\n",
      " 13  split6_test_score  10 non-null     float64\n",
      " 14  split7_test_score  10 non-null     float64\n",
      " 15  split8_test_score  10 non-null     float64\n",
      " 16  split9_test_score  10 non-null     float64\n",
      " 17  mean_test_score    10 non-null     float64\n",
      " 18  std_test_score     10 non-null     float64\n",
      " 19  rank_test_score    20 non-null     int32  \n",
      "dtypes: float64(16), int32(1), object(3)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time results = grid_cv.cv_results_\n",
    "\n",
    "df1 = pd.DataFrame(results)\n",
    "display(df1.head(35))\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbswP-9vC_Rd",
    "outputId": "38d95613-e68f-4e54-f948-512f42c4b986"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.818513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>l2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.812345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.800036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>l2</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.795409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.672944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.439139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.437152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.437152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>l1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>l1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>l1</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>l1</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_penalty param_C  mean_test_score\n",
       "13            l2      10         0.818513\n",
       "15            l2     100         0.812345\n",
       "17            l2    1000         0.800036\n",
       "19            l2   10000         0.795409\n",
       "11            l2       1         0.774321\n",
       "9             l2     0.1         0.672944\n",
       "7             l2    0.01         0.562997\n",
       "5             l2   0.001         0.439139\n",
       "1             l2   1e-05         0.437152\n",
       "3             l2  0.0001         0.437152\n",
       "0             l1   1e-05              NaN\n",
       "2             l1  0.0001              NaN\n",
       "4             l1   0.001              NaN\n",
       "6             l1    0.01              NaN\n",
       "8             l1     0.1              NaN\n",
       "10            l1       1              NaN\n",
       "12            l1      10              NaN\n",
       "14            l1     100              NaN\n",
       "16            l1    1000              NaN\n",
       "18            l1   10000              NaN"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1[['param_penalty','param_C', 'mean_test_score']]\n",
    "df1 = df1.sort_values(by='mean_test_score', ascending = False)\n",
    "df1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "covid19-tweets-sentiment-analysis-nlp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 3889.575075,
   "end_time": "2021-02-14T13:29:29.031663",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-14T12:24:39.456588",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
