{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEX5Kk90DSGS",
    "outputId": "8d04f9e5-1a91-4678-ba33-a269b41d4122"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sF1azMHDC_Q-"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yk2ky07-C_RA"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score,  accuracy_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score,  accuracy_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D50G4l0SC_RA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7aht-HZC_RB",
    "outputId": "da9b097a-0900-4f8f-b500-c35f03c33381"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWGibQmRC_RB",
    "outputId": "862c812c-d2b5-443c-e35e-dc5daf2fba70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emot in /Users/kgarg/opt/anaconda3/lib/python3.8/site-packages (2.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbOpjZOUKz40",
    "outputId": "355a85bf-91de-46f2-eb9e-3bc5bf3c49be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.6.2-py3-none-any.whl (2.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9AVjkrtaC_RC"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "KYGb9A4IC_RC"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/Corona_NLP_train.csv', encoding=\"ISO-8859-1\", low_memory=False)\n",
    "test = pd.read_csv('./data/Corona_NLP_test.csv', encoding=\"ISO-8859-1\", low_memory=False) \n",
    "df = train.append(test, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "jw9JFgGgC_RE"
   },
   "outputs": [],
   "source": [
    "# -- filling missing values\n",
    "df['Location'].fillna(value='unknown', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "vE-GHkyGC_RE"
   },
   "outputs": [],
   "source": [
    "# -- label encoding \n",
    "encoding = {'Extremely Negative': 'Negative',\n",
    "            'Extremely Positive': 'Positive'\n",
    "           }\n",
    "labels = ['Negative', 'Positive']\n",
    "df['Sentiment'].replace(encoding, inplace=True)\n",
    "df[\"sentiment\"] = LabelEncoder().fit_transform(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "3MKNdTFCC_RG"
   },
   "outputs": [],
   "source": [
    "# -- remove URLs\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# -- remove HTML\n",
    "def html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(remove_urls)\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "UXbuAXvlC_RH"
   },
   "outputs": [],
   "source": [
    "# -- lowercase\n",
    "df['OriginalTweet'] = df['OriginalTweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "n3RgoyTKC_RH"
   },
   "outputs": [],
   "source": [
    "# -- convert emojis and emoticons to words\n",
    "def convert_emojis_emoticons(text):\n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(convert_emojis_emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "qwibfPcyC_RO"
   },
   "outputs": [],
   "source": [
    "# -- remove special and non-ASCII characters\n",
    "def clean(tweet): \n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â²\", \"\", tweet)\n",
    "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â¹\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â½\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â¾\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼berweist\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼cretsiz\", \"\", tweet)\n",
    "    tweet = re.sub(r\"zã¼rich\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼retime\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "    tweet = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'mentioned', tweet)\n",
    "    tweet = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'referance', tweet)\n",
    "    tweet = re.sub(r'£|\\$', 'money', tweet)\n",
    "    tweet = re.sub(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b', ' ', tweet)\n",
    "    tweet = re.sub(r'\\d+(\\.\\d+)?', ' ', tweet) \n",
    "    tweet = re.sub(r'[^\\w\\d\\s]', ' ', tweet)\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    tweet = re.sub(r'^\\s+|\\s+?$', '', tweet.lower())\n",
    "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
    "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
    "    tweet = re.sub(r\"&amp;\", \"&\", tweet) \n",
    "    tweet = re.sub(r\"_\", \"  \", tweet)\n",
    "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
    "    for p in punctuations:\n",
    "        tweet = tweet.replace(p, f' {p} ')\n",
    "    return str(tweet)\n",
    "\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "QWAIdXXiX7R3"
   },
   "outputs": [],
   "source": [
    "# -- spellcheck and keep words that are in the English dictionary\n",
    "spell = SpellChecker(distance = 1, language='en')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else: \n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "def ensure_english(text):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(text) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(correct_spellings)\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(ensure_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "th8JB9tjC_RP"
   },
   "outputs": [],
   "source": [
    "# -- remove punctuation\n",
    "import string\n",
    "regular_punct = list(string.punctuation)\n",
    "def remove_punctuation(text):\n",
    "    for punc in regular_punct:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, ' ')\n",
    "    return text.strip()\n",
    "\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- remove stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "def remove_stopwords(tweet):\n",
    "  tweet = tweet.split()\n",
    "  tweet = \" \".join([word for word in tweet if not word in en_stops])  \n",
    "  return tweet\n",
    "\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current situation good'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('The current situation is not good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "H1ts6loeC_RT"
   },
   "outputs": [],
   "source": [
    "# -- tokenize\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "IJ6iapoCC_RU"
   },
   "outputs": [],
   "source": [
    "# -- lematize\n",
    "lem = WordNetLemmatizer()\n",
    "def lemma_wordnet(input):\n",
    "    return [lem.lemmatize(w) for w in input]\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(lemma_wordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "XKrQG5dAC_RU"
   },
   "outputs": [],
   "source": [
    "# -- combine individual words\n",
    "def combine_text(input):\n",
    "    combined = ' '.join(input)\n",
    "    return combined\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(combine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "oWrB8wTFYDep",
    "outputId": "9060e9a2-031f-4b0b-a242-262052933633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201                                       hearing multiple mandatory quarantine coming week u last chance stock food take warning late\n",
      "202     stock amid outbreak latest extent damage share several key tech medium auto transportation travel retail consumer good banking\n",
      "203                                                                  lot u going self isolation week thought useful article sane happy\n",
      "204                                     panic today following impending ministry domestic trade consumer people spread fake news panic\n",
      "205    increasingly global spread beginning panic grocery becoming increasingly chaotic animalistic nature survival starting hoard cut\n",
      "206                                                         panic street food saffron flapjack nose food drink writer usual say recipe\n",
      "207                                                                                            important update regarding retail store\n",
      "208        pregnant make sure date wash frequently stay away people protect health common sense way march chief medical health officer\n",
      "209                                                                 free delivery service fee la supermarket special older amid crisis\n",
      "Name: OriginalTweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth=200\n",
    "print(df['OriginalTweet'][201:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "SVXO9Y-8C_RU"
   },
   "outputs": [],
   "source": [
    "# -- split into testing and testing set\n",
    "train, test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "id": "v48ujX1fC_RV"
   },
   "outputs": [],
   "source": [
    "# -- Bag of words\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_train_bow = cv.fit_transform(train['OriginalTweet']) \n",
    "Y_train_bow = train['sentiment'] \n",
    "X_test_bow = cv.transform(test['OriginalTweet'])\n",
    "Y_test_bow = test['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Bag of words - bigrams\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_bbow = cv.fit_transform(train['OriginalTweet']) \n",
    "X_test_bbow = cv.transform(test['OriginalTweet']) \n",
    "Y_train_bbow = train['sentiment']\n",
    "Y_test_bbow = test['sentiment']\n",
    "\n",
    "# -- TF-IDF\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm = None)\n",
    "vectorizer.fit(train)\n",
    "X_train_tfidf = vectorizer.fit_transform(train['OriginalTweet'])\n",
    "X_test_tfidf = train['sentiment'] \n",
    "Y_train_tdidf =vectorizer.transform(test['OriginalTweet']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11239, 228214)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "8NYhp501C_RV",
    "outputId": "c80277c1-6b9f-4bf4-baeb-9200a618e2c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bow-TF:IDF :'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(33716, 228214)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>aba list</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandon also</th>\n",
       "      <th>abandon food</th>\n",
       "      <th>abandon need</th>\n",
       "      <th>abandon supermarket</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoned chilled</th>\n",
       "      <th>abandoned fate</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom see</th>\n",
       "      <th>zoom shopping</th>\n",
       "      <th>zoom strategy</th>\n",
       "      <th>zoom toilet</th>\n",
       "      <th>zoom variety</th>\n",
       "      <th>zoom video</th>\n",
       "      <th>zoonotic</th>\n",
       "      <th>zoonotic deeply</th>\n",
       "      <th>zoonotic disease</th>\n",
       "      <th>zoonotic waiting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 228214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  aba list  abandon  abandon also  abandon food  abandon need  \\\n",
       "0    0         0        0             0             0             0   \n",
       "1    0         0        0             0             0             0   \n",
       "2    0         0        0             0             0             0   \n",
       "3    0         0        0             0             0             0   \n",
       "4    0         0        0             0             0             0   \n",
       "\n",
       "   abandon supermarket  abandoned  abandoned chilled  abandoned fate  ...  \\\n",
       "0                    0          0                  0               0  ...   \n",
       "1                    0          0                  0               0  ...   \n",
       "2                    0          0                  0               0  ...   \n",
       "3                    0          0                  0               0  ...   \n",
       "4                    0          0                  0               0  ...   \n",
       "\n",
       "   zoom see  zoom shopping  zoom strategy  zoom toilet  zoom variety  \\\n",
       "0         0              0              0            0             0   \n",
       "1         0              0              0            0             0   \n",
       "2         0              0              0            0             0   \n",
       "3         0              0              0            0             0   \n",
       "4         0              0              0            0             0   \n",
       "\n",
       "   zoom video  zoonotic  zoonotic deeply  zoonotic disease  zoonotic waiting  \n",
       "0           0         0                0                 0                 0  \n",
       "1           0         0                0                 0                 0  \n",
       "2           0         0                0                 0                 0  \n",
       "3           0         0                0                 0                 0  \n",
       "4           0         0                0                 0                 0  \n",
       "\n",
       "[5 rows x 228214 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Bow-TF:IDF :\", X_train_bbow.shape)\n",
    "df_tfidf = pd.DataFrame(X_train_bbow.toarray(), columns=cv.get_feature_names())\n",
    "display(df_tfidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "id": "z7c9aFuVC_RW",
    "outputId": "509a7016-9525-4449-af87-8e97ac9e9266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.60038553 0.59246626 0.60151268 0.58935192 0.5875723 ]\n",
      "0.5942577373416024\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.59311981 0.58371645 0.59587721 0.58341984 0.58416135]\n",
      "0.5880589316384338\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.5569395  0.5571704  0.56102625 0.53937417 0.557467  ]\n",
      "0.5543954637549524\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.65880783 0.65312176 0.65757081 0.64674477 0.65163874]\n",
      "0.6535767816156256\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.64516607 0.64214741 0.64526175 0.63695684 0.63636364]\n",
      "0.6411791438210426\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.62841044 0.62346137 0.62820703 0.62212665 0.62538929]\n",
      "0.625518955644701\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6551294599163626"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- multinomialNB with bag of word\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_bbow, Y_train_bbow, cv=5)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_bbow, Y_train_bbow)\n",
    "clf.score(X_test_bbow, Y_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "id": "C4B0It9ZC_RW",
    "outputId": "bc355275-2945-49b7-bb14-a470f33c7569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  175.0\n",
      "[0.63523132 0.63013495 0.63651194 0.62820703 0.62894854]\n",
      "0.6318067557076457\n",
      "\n",
      "\n",
      "alpha:  200.0\n",
      "[0.63182088 0.62716892 0.63443571 0.62642741 0.62746552]\n",
      "0.6294636861670526\n",
      "\n",
      "\n",
      "alpha:  225.0\n",
      "[0.628707   0.62553759 0.63206288 0.62183005 0.62524099]\n",
      "0.6266757020021114\n",
      "\n",
      "\n",
      "alpha:  250.0\n",
      "[0.62692764 0.62286816 0.62909684 0.62019872 0.62449948]\n",
      "0.6247181691342316\n",
      "\n",
      "\n",
      "alpha:  300.0\n",
      "[0.62396204 0.61752929 0.62375797 0.61663948 0.62079193]\n",
      "0.6205361423093481\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with TF-IDF\n",
    "alpha = [175.0, 200.0, 225.0, 250.0, 300.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_tfidf, X_test_tfidf, cv=5)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "id": "p0O4c1bVC_RZ"
   },
   "outputs": [],
   "source": [
    "# -- decision tree classifier with BoW\n",
    "dtclassifier=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None)\n",
    "dtclassifier.fit(X_train_bow, Y_train_bow)\n",
    "preddt = dtclassifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "id": "O6sZIkRCC_RZ",
    "outputId": "d7a6c598-e06c-4d6f-d694-17af5d0c26c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6943678263190676\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_bow)\n",
    "print(accuracy)\n",
    "# unigram: .69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "id": "K2t4tRpGC_Ra"
   },
   "outputs": [],
   "source": [
    "# -- decision tree classifier with tf-idf\n",
    "dtclassifier=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None) \n",
    "dtclassifier.fit(X_train_tfidf,train['sentiment'])\n",
    "preddt = dtclassifier.predict(Y_train_tdidf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "id": "6ecSbdERC_Ra",
    "outputId": "cd48ef80-cf60-4b51-d19f-e32eb15f514d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6932111397811194\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "VpSxAE6_C_Ra"
   },
   "outputs": [],
   "source": [
    "# -- decision tree classifier with hashing \n",
    "dtclassifier=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None)\n",
    "dtclassifier.fit(X_train_hash,train['sentiment'])\n",
    "preddt = dtclassifier.predict(Y_train_hash) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "SJJ5V8VGT8SV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641427173236053\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "zAK_EPAqC_Rb"
   },
   "outputs": [],
   "source": [
    "# -- td-idf vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "vectors = vectorizer.fit_transform(df['OriginalTweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "Gk6zW1asC_Rb"
   },
   "outputs": [],
   "source": [
    "test_vectors = vectors[40000:]\n",
    "train_vectors = vectors[:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "3SQdF6eqC_Rb",
    "outputId": "f4e9fdda-9853-4141-fb94-3099fc06f3d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVC(kernel=linear)\n",
      "Training time: 192.519107s; Prediction time: 10.509840s\n",
      "positive:  {'precision': 0.807565011820331, 'recall': 0.8275193798449613, 'f1-score': 0.8174204355108878, 'support': 2064}\n",
      "negative:  {'precision': 0.8050153531218014, 'recall': 0.77145659637077, 'f1-score': 0.787878787878788, 'support': 2039}\n",
      "notr:  {'precision': 0.6896162528216704, 'recall': 0.7171361502347418, 'f1-score': 0.7031070195627156, 'support': 852}\n"
     ]
    }
   ],
   "source": [
    "# -- SVM, kernel=linear\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(train_vectors, df['Sentiment'][:40000])\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "# results\n",
    "print(\"Results for SVC(kernel=linear)\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = classification_report(df['Sentiment'][40000:], prediction_linear, output_dict=True)\n",
    "print('positive: ', report['Positive'])\n",
    "print('negative: ', report['Negative'])\n",
    "print('notr: ', report['Neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "4gHmw2XNC_Rb",
    "outputId": "4065b3bf-7844-418e-fc30-41dc0463aa52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neutral']\n"
     ]
    }
   ],
   "source": [
    "review = \"\"\"give elderly disabled shopping amid outbreak\"\"\"\n",
    "review_vector = vectorizer.transform([review]) # vectorizing\n",
    "print(classifier_linear.predict(review_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "id": "6k6epXw-C_Rb",
    "outputId": "0e283bf4-085d-40da-d89d-544064f67b7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -- logistic regression with hashing \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class=\"ovr\")\n",
    "log_reg.fit(X_train_bbow, X_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11239x228214 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 181700 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_bbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "id": "3SKYyCzjC_Rc",
    "outputId": "6c3fab93-a275-427f-e550-428fecad07e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7882373876679419"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy = log_reg.score(X_train_bbow, Y_train_bbow)\n",
    "test_accuracy = log_reg.score(X_test_bbow, Y_test_bbow)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "lne6gnDCC_Rc",
    "outputId": "6243e866-48f7-421c-ca6c-5417f3401400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial (Softmax)\n",
      "--------------------\n",
      "Accuracy on Train Data : 0.83\n",
      "Accuracy on Test Data  : 0.78\n"
     ]
    }
   ],
   "source": [
    "log_reg_mnm = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "log_reg_mnm.fit(X_train_hash, X_test_hash)\n",
    "\n",
    "train_accuracy = log_reg_mnm.score(X_train_hash, X_test_hash)\n",
    "test_accuracy = log_reg_mnm.score(Y_train_hash, Y_test)\n",
    "\n",
    "print('Multinomial (Softmax)', '-'*20, \n",
    "      'Accuracy on Train Data : {:.2f}'.format(train_accuracy), \n",
    "      'Accuracy on Test Data  : {:.2f}'.format(test_accuracy), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "fVDYoV1DC_Rc",
    "outputId": "afd36e64-3249-4fed-ba18-bc1c7e8de377"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_values</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.476361</td>\n",
       "      <td>0.479224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.590728</td>\n",
       "      <td>0.584216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.719213</td>\n",
       "      <td>0.697482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.829962</td>\n",
       "      <td>0.775514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.868668</td>\n",
       "      <td>0.783522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.874184</td>\n",
       "      <td>0.774980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.874659</td>\n",
       "      <td>0.773200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_values  Train Accuracy  Test Accuracy\n",
       "0     0.001        0.476361       0.479224\n",
       "1     0.010        0.590728       0.584216\n",
       "2     0.100        0.719213       0.697482\n",
       "3     1.000        0.829962       0.775514\n",
       "4    10.000        0.868668       0.783522\n",
       "5   100.000        0.874184       0.774980\n",
       "6  1000.000        0.874659       0.773200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- validation for multinomial log reg \n",
    "C_values = [0.001,0.01, 0.1,1,10,100, 1000]\n",
    "\n",
    "accuracy_values = pd.DataFrame(columns=['C_values', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "for c in C_values:\n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(penalty = 'l2', C = c, random_state = 0, solver='lbfgs', multi_class='multinomial')\n",
    "    lr.fit(X_train_hash, X_test_hash)\n",
    "    accuracy_values = accuracy_values.append({'C_values': c,\n",
    "                                              'Train Accuracy': lr.score(X_train_hash, X_test_hash),\n",
    "                                              'Test Accuracy': lr.score(Y_train_hash, Y_test)\n",
    "                                             }, ignore_index=True)\n",
    "display(accuracy_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJbMApy1C_Rc"
   },
   "outputs": [],
   "source": [
    "# -- grid search\n",
    "parameters = {\"C\": [10 ** x for x in range (-5, 5, 1)],\n",
    "              \"penalty\": ['l1', 'l2']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plzyULwvC_Rc",
    "outputId": "39121d6c-46ca-4aeb-c2a5-23264363b5b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(multi_class='ovr'),\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000, 10000],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_cv = GridSearchCV(estimator=log_reg,\n",
    "                       param_grid = parameters,\n",
    "                       cv = 10\n",
    "                      )\n",
    "\n",
    "grid_cv.fit(X_train_hash, X_test_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvYh6Su_C_Rd",
    "outputId": "e3657790-b054-46ec-8b5c-3ee8c62c9969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters :  {'C': 10, 'penalty': 'l2'}\n",
      "Best Score      :  0.8185134316740406\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters : \", grid_cv.best_params_)\n",
    "print(\"Best Score      : \", grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDnHvC_AC_Rd",
    "outputId": "f8289337-6d4d-4f38-a56a-74322e3f0866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 11.2 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.313961</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l2'}</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437152</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.190604</td>\n",
       "      <td>0.081269</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437152</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.347032</td>\n",
       "      <td>0.042141</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.438019</td>\n",
       "      <td>0.439798</td>\n",
       "      <td>0.438909</td>\n",
       "      <td>0.438019</td>\n",
       "      <td>0.438909</td>\n",
       "      <td>0.439502</td>\n",
       "      <td>0.439632</td>\n",
       "      <td>0.439929</td>\n",
       "      <td>0.439039</td>\n",
       "      <td>0.439632</td>\n",
       "      <td>0.439139</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.741687</td>\n",
       "      <td>0.069908</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>0.575030</td>\n",
       "      <td>0.559312</td>\n",
       "      <td>0.567023</td>\n",
       "      <td>0.551008</td>\n",
       "      <td>0.570285</td>\n",
       "      <td>0.564947</td>\n",
       "      <td>0.557995</td>\n",
       "      <td>0.563631</td>\n",
       "      <td>0.564818</td>\n",
       "      <td>0.555918</td>\n",
       "      <td>0.562997</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.001108</td>\n",
       "      <td>0.650369</td>\n",
       "      <td>0.011164</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.684164</td>\n",
       "      <td>0.673488</td>\n",
       "      <td>0.678826</td>\n",
       "      <td>0.653025</td>\n",
       "      <td>0.682681</td>\n",
       "      <td>0.668743</td>\n",
       "      <td>0.674281</td>\n",
       "      <td>0.680510</td>\n",
       "      <td>0.673984</td>\n",
       "      <td>0.659745</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38.848168</td>\n",
       "      <td>2.187563</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.784401</td>\n",
       "      <td>0.776394</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.762159</td>\n",
       "      <td>0.784994</td>\n",
       "      <td>0.770463</td>\n",
       "      <td>0.773658</td>\n",
       "      <td>0.775734</td>\n",
       "      <td>0.785227</td>\n",
       "      <td>0.762978</td>\n",
       "      <td>0.774321</td>\n",
       "      <td>0.008267</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>41.995080</td>\n",
       "      <td>0.480354</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.827699</td>\n",
       "      <td>0.814650</td>\n",
       "      <td>0.810202</td>\n",
       "      <td>0.814353</td>\n",
       "      <td>0.826216</td>\n",
       "      <td>0.819098</td>\n",
       "      <td>0.819045</td>\n",
       "      <td>0.815188</td>\n",
       "      <td>0.823791</td>\n",
       "      <td>0.814892</td>\n",
       "      <td>0.818513</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 100, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>41.145590</td>\n",
       "      <td>0.834779</td>\n",
       "      <td>0.013074</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "      <td>0.816726</td>\n",
       "      <td>0.797450</td>\n",
       "      <td>0.803974</td>\n",
       "      <td>0.808126</td>\n",
       "      <td>0.820285</td>\n",
       "      <td>0.811388</td>\n",
       "      <td>0.815485</td>\n",
       "      <td>0.812519</td>\n",
       "      <td>0.819341</td>\n",
       "      <td>0.818155</td>\n",
       "      <td>0.812345</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41.099051</td>\n",
       "      <td>0.950770</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l2'}</td>\n",
       "      <td>0.801601</td>\n",
       "      <td>0.792705</td>\n",
       "      <td>0.797746</td>\n",
       "      <td>0.793298</td>\n",
       "      <td>0.804567</td>\n",
       "      <td>0.801008</td>\n",
       "      <td>0.798576</td>\n",
       "      <td>0.798279</td>\n",
       "      <td>0.803916</td>\n",
       "      <td>0.808662</td>\n",
       "      <td>0.800036</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10000, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40.524569</td>\n",
       "      <td>0.326188</td>\n",
       "      <td>0.011391</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>10000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10000, 'penalty': 'l2'}</td>\n",
       "      <td>0.800119</td>\n",
       "      <td>0.790629</td>\n",
       "      <td>0.793001</td>\n",
       "      <td>0.780546</td>\n",
       "      <td>0.808719</td>\n",
       "      <td>0.793891</td>\n",
       "      <td>0.795313</td>\n",
       "      <td>0.795313</td>\n",
       "      <td>0.797983</td>\n",
       "      <td>0.798576</td>\n",
       "      <td>0.795409</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.002367      0.000275         0.000000        0.000000   1e-05   \n",
       "1        3.313961      0.044434         0.010587        0.000077   1e-05   \n",
       "2        0.002228      0.000192         0.000000        0.000000  0.0001   \n",
       "3        3.190604      0.081269         0.011091        0.001986  0.0001   \n",
       "4        0.002420      0.000151         0.000000        0.000000   0.001   \n",
       "5        3.347032      0.042141         0.011306        0.002212   0.001   \n",
       "6        0.002300      0.000184         0.000000        0.000000    0.01   \n",
       "7        6.741687      0.069908         0.011410        0.002420    0.01   \n",
       "8        0.002367      0.000176         0.000000        0.000000     0.1   \n",
       "9       17.001108      0.650369         0.011164        0.001499     0.1   \n",
       "10       0.002403      0.000193         0.000000        0.000000       1   \n",
       "11      38.848168      2.187563         0.010815        0.000472       1   \n",
       "12       0.002316      0.000240         0.000000        0.000000      10   \n",
       "13      41.995080      0.480354         0.010693        0.000114      10   \n",
       "14       0.002336      0.000187         0.000000        0.000000     100   \n",
       "15      41.145590      0.834779         0.013074        0.007048     100   \n",
       "16       0.002140      0.000289         0.000000        0.000000    1000   \n",
       "17      41.099051      0.950770         0.010516        0.000163    1000   \n",
       "18       0.002234      0.000265         0.000000        0.000000   10000   \n",
       "19      40.524569      0.326188         0.011391        0.002111   10000   \n",
       "\n",
       "   param_penalty                          params  split0_test_score  \\\n",
       "0             l1   {'C': 1e-05, 'penalty': 'l1'}                NaN   \n",
       "1             l2   {'C': 1e-05, 'penalty': 'l2'}           0.437129   \n",
       "2             l1  {'C': 0.0001, 'penalty': 'l1'}                NaN   \n",
       "3             l2  {'C': 0.0001, 'penalty': 'l2'}           0.437129   \n",
       "4             l1   {'C': 0.001, 'penalty': 'l1'}                NaN   \n",
       "5             l2   {'C': 0.001, 'penalty': 'l2'}           0.438019   \n",
       "6             l1    {'C': 0.01, 'penalty': 'l1'}                NaN   \n",
       "7             l2    {'C': 0.01, 'penalty': 'l2'}           0.575030   \n",
       "8             l1     {'C': 0.1, 'penalty': 'l1'}                NaN   \n",
       "9             l2     {'C': 0.1, 'penalty': 'l2'}           0.684164   \n",
       "10            l1       {'C': 1, 'penalty': 'l1'}                NaN   \n",
       "11            l2       {'C': 1, 'penalty': 'l2'}           0.784401   \n",
       "12            l1      {'C': 10, 'penalty': 'l1'}                NaN   \n",
       "13            l2      {'C': 10, 'penalty': 'l2'}           0.827699   \n",
       "14            l1     {'C': 100, 'penalty': 'l1'}                NaN   \n",
       "15            l2     {'C': 100, 'penalty': 'l2'}           0.816726   \n",
       "16            l1    {'C': 1000, 'penalty': 'l1'}                NaN   \n",
       "17            l2    {'C': 1000, 'penalty': 'l2'}           0.801601   \n",
       "18            l1   {'C': 10000, 'penalty': 'l1'}                NaN   \n",
       "19            l2   {'C': 10000, 'penalty': 'l2'}           0.800119   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.436833           0.437129           0.437129   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.436833           0.437129           0.437129   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.439798           0.438909           0.438019   \n",
       "6                 NaN                NaN                NaN   \n",
       "7            0.559312           0.567023           0.551008   \n",
       "8                 NaN                NaN                NaN   \n",
       "9            0.673488           0.678826           0.653025   \n",
       "10                NaN                NaN                NaN   \n",
       "11           0.776394           0.767200           0.762159   \n",
       "12                NaN                NaN                NaN   \n",
       "13           0.814650           0.810202           0.814353   \n",
       "14                NaN                NaN                NaN   \n",
       "15           0.797450           0.803974           0.808126   \n",
       "16                NaN                NaN                NaN   \n",
       "17           0.792705           0.797746           0.793298   \n",
       "18                NaN                NaN                NaN   \n",
       "19           0.790629           0.793001           0.780546   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.437129           0.437129           0.437259   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.437129           0.437129           0.437259   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.438909           0.439502           0.439632   \n",
       "6                 NaN                NaN                NaN   \n",
       "7            0.570285           0.564947           0.557995   \n",
       "8                 NaN                NaN                NaN   \n",
       "9            0.682681           0.668743           0.674281   \n",
       "10                NaN                NaN                NaN   \n",
       "11           0.784994           0.770463           0.773658   \n",
       "12                NaN                NaN                NaN   \n",
       "13           0.826216           0.819098           0.819045   \n",
       "14                NaN                NaN                NaN   \n",
       "15           0.820285           0.811388           0.815485   \n",
       "16                NaN                NaN                NaN   \n",
       "17           0.804567           0.801008           0.798576   \n",
       "18                NaN                NaN                NaN   \n",
       "19           0.808719           0.793891           0.795313   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0                 NaN                NaN                NaN              NaN   \n",
       "1            0.437259           0.437259           0.437259         0.437152   \n",
       "2                 NaN                NaN                NaN              NaN   \n",
       "3            0.437259           0.437259           0.437259         0.437152   \n",
       "4                 NaN                NaN                NaN              NaN   \n",
       "5            0.439929           0.439039           0.439632         0.439139   \n",
       "6                 NaN                NaN                NaN              NaN   \n",
       "7            0.563631           0.564818           0.555918         0.562997   \n",
       "8                 NaN                NaN                NaN              NaN   \n",
       "9            0.680510           0.673984           0.659745         0.672944   \n",
       "10                NaN                NaN                NaN              NaN   \n",
       "11           0.775734           0.785227           0.762978         0.774321   \n",
       "12                NaN                NaN                NaN              NaN   \n",
       "13           0.815188           0.823791           0.814892         0.818513   \n",
       "14                NaN                NaN                NaN              NaN   \n",
       "15           0.812519           0.819341           0.818155         0.812345   \n",
       "16                NaN                NaN                NaN              NaN   \n",
       "17           0.798279           0.803916           0.808662         0.800036   \n",
       "18                NaN                NaN                NaN              NaN   \n",
       "19           0.795313           0.797983           0.798576         0.795409   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0              NaN               20  \n",
       "1         0.000123                9  \n",
       "2              NaN               18  \n",
       "3         0.000123                9  \n",
       "4              NaN               15  \n",
       "5         0.000656                8  \n",
       "6              NaN               11  \n",
       "7         0.006738                7  \n",
       "8              NaN               12  \n",
       "9         0.009510                6  \n",
       "10             NaN               14  \n",
       "11        0.008267                5  \n",
       "12             NaN               16  \n",
       "13        0.005456                1  \n",
       "14             NaN               17  \n",
       "15        0.006968                2  \n",
       "16             NaN               19  \n",
       "17        0.004722                3  \n",
       "18             NaN               13  \n",
       "19        0.006840                4  "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   mean_fit_time      20 non-null     float64\n",
      " 1   std_fit_time       20 non-null     float64\n",
      " 2   mean_score_time    20 non-null     float64\n",
      " 3   std_score_time     20 non-null     float64\n",
      " 4   param_C            20 non-null     object \n",
      " 5   param_penalty      20 non-null     object \n",
      " 6   params             20 non-null     object \n",
      " 7   split0_test_score  10 non-null     float64\n",
      " 8   split1_test_score  10 non-null     float64\n",
      " 9   split2_test_score  10 non-null     float64\n",
      " 10  split3_test_score  10 non-null     float64\n",
      " 11  split4_test_score  10 non-null     float64\n",
      " 12  split5_test_score  10 non-null     float64\n",
      " 13  split6_test_score  10 non-null     float64\n",
      " 14  split7_test_score  10 non-null     float64\n",
      " 15  split8_test_score  10 non-null     float64\n",
      " 16  split9_test_score  10 non-null     float64\n",
      " 17  mean_test_score    10 non-null     float64\n",
      " 18  std_test_score     10 non-null     float64\n",
      " 19  rank_test_score    20 non-null     int32  \n",
      "dtypes: float64(16), int32(1), object(3)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time results = grid_cv.cv_results_\n",
    "\n",
    "df1 = pd.DataFrame(results)\n",
    "display(df1.head(35))\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbswP-9vC_Rd",
    "outputId": "38d95613-e68f-4e54-f948-512f42c4b986"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.818513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>l2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.812345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.800036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>l2</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.795409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.672944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.439139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.437152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.437152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>l1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>l1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>l1</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>l1</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_penalty param_C  mean_test_score\n",
       "13            l2      10         0.818513\n",
       "15            l2     100         0.812345\n",
       "17            l2    1000         0.800036\n",
       "19            l2   10000         0.795409\n",
       "11            l2       1         0.774321\n",
       "9             l2     0.1         0.672944\n",
       "7             l2    0.01         0.562997\n",
       "5             l2   0.001         0.439139\n",
       "1             l2   1e-05         0.437152\n",
       "3             l2  0.0001         0.437152\n",
       "0             l1   1e-05              NaN\n",
       "2             l1  0.0001              NaN\n",
       "4             l1   0.001              NaN\n",
       "6             l1    0.01              NaN\n",
       "8             l1     0.1              NaN\n",
       "10            l1       1              NaN\n",
       "12            l1      10              NaN\n",
       "14            l1     100              NaN\n",
       "16            l1    1000              NaN\n",
       "18            l1   10000              NaN"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1[['param_penalty','param_C', 'mean_test_score']]\n",
    "df1 = df1.sort_values(by='mean_test_score', ascending = False)\n",
    "df1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "covid19-tweets-sentiment-analysis-nlp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 3889.575075,
   "end_time": "2021-02-14T13:29:29.031663",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-14T12:24:39.456588",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
