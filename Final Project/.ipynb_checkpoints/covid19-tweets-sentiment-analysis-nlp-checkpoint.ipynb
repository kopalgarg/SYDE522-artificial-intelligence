{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "sF1azMHDC_Q-"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "yk2ky07-C_RA"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score,  accuracy_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score,  accuracy_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "D50G4l0SC_RA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7aht-HZC_RB",
    "outputId": "da9b097a-0900-4f8f-b500-c35f03c33381"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWGibQmRC_RB",
    "outputId": "862c812c-d2b5-443c-e35e-dc5daf2fba70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emot in /Users/kgarg/opt/anaconda3/lib/python3.8/site-packages (2.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbOpjZOUKz40",
    "outputId": "355a85bf-91de-46f2-eb9e-3bc5bf3c49be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in /Users/kgarg/opt/anaconda3/lib/python3.8/site-packages (0.6.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "9AVjkrtaC_RC"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473506"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OriginalTweet'].str.lower().str.split().apply(len).sum()\n",
    "pd.options.display.max_colwidth=200\n",
    "df['OriginalTweet'][3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "KYGb9A4IC_RC"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/Corona_NLP_train.csv', encoding=\"ISO-8859-1\", low_memory=False)\n",
    "test = pd.read_csv('./data/Corona_NLP_test.csv', encoding=\"ISO-8859-1\", low_memory=False) \n",
    "#df = train.append(test, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "jw9JFgGgC_RE"
   },
   "outputs": [],
   "source": [
    "# -- filling missing values\n",
    "train['Location'].fillna(value='unknown', inplace=True) \n",
    "test['Location'].fillna(value='unknown', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "vE-GHkyGC_RE"
   },
   "outputs": [],
   "source": [
    "# -- label encoding \n",
    "encoding = {'Extremely Negative': 'Negative',\n",
    "            'Extremely Positive': 'Positive'\n",
    "           }\n",
    "labels = ['Negative', 'Positive']\n",
    "train['Sentiment'].replace(encoding, inplace=True)\n",
    "train[\"sentiment\"] = LabelEncoder().fit_transform(train[\"Sentiment\"])\n",
    "\n",
    "test['Sentiment'].replace(encoding, inplace=True)\n",
    "test[\"sentiment\"] = LabelEncoder().fit_transform(test[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "3MKNdTFCC_RG"
   },
   "outputs": [],
   "source": [
    "# -- remove URLs\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# -- remove HTML\n",
    "def html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_urls)\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(html)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(remove_urls)\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "UXbuAXvlC_RH"
   },
   "outputs": [],
   "source": [
    "# -- lowercase\n",
    "train['OriginalTweet'] = train['OriginalTweet'].str.lower()\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "n3RgoyTKC_RH"
   },
   "outputs": [],
   "source": [
    "# -- convert emojis and emoticons to words\n",
    "def convert_emojis_emoticons(text):\n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(convert_emojis_emoticons)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(convert_emojis_emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "qwibfPcyC_RO"
   },
   "outputs": [],
   "source": [
    "# -- remove special and non-ASCII characters\n",
    "def clean(tweet): \n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â²\", \"\", tweet)\n",
    "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â¹\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â½\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â¾\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼berweist\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼cretsiz\", \"\", tweet)\n",
    "    tweet = re.sub(r\"zã¼rich\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼retime\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "    tweet = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'mentioned', tweet)\n",
    "    tweet = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'referance', tweet)\n",
    "    tweet = re.sub(r'£|\\$', 'money', tweet)\n",
    "    tweet = re.sub(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b', ' ', tweet)\n",
    "    tweet = re.sub(r'\\d+(\\.\\d+)?', ' ', tweet) \n",
    "    tweet = re.sub(r'[^\\w\\d\\s]', ' ', tweet)\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    tweet = re.sub(r'^\\s+|\\s+?$', '', tweet.lower())\n",
    "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
    "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
    "    tweet = re.sub(r\"&amp;\", \"&\", tweet) \n",
    "    tweet = re.sub(r\"_\", \"  \", tweet)\n",
    "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
    "    for p in punctuations:\n",
    "        tweet = tweet.replace(p, f' {p} ')\n",
    "    return str(tweet)\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(clean)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "QWAIdXXiX7R3"
   },
   "outputs": [],
   "source": [
    "# -- spellcheck and keep words that are in the English dictionary\n",
    "spell = SpellChecker(distance = 1, language='en')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else: \n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "def ensure_english(text):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(text) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(correct_spellings)\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(ensure_english)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(correct_spellings)\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(ensure_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>new encounter empty supermarket pictured sold stock</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>find hand turned money pack check driving</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>unknown</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>find protect</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>panic city anxious stock food medical worker becomes confirmed patient staged event canon canon canon election</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>news one week everyone baby milk powder next everyone toilet paper</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>3794</td>\n",
       "      <td>48746</td>\n",
       "      <td>Israel ??</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>meanwhile supermarket people dance sing together stay positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>3795</td>\n",
       "      <td>48747</td>\n",
       "      <td>Farmington, NM</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>panic buy lot non perishable echo need food also looking pack screened sure</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>3796</td>\n",
       "      <td>48748</td>\n",
       "      <td>Haverford, PA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>prof economics talking recent research impact economy watch starting happy face confusion</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>3797</td>\n",
       "      <td>48749</td>\n",
       "      <td>unknown</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>need instead bear assume even worst supermarket crowded like hell virus tu</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>3798</td>\n",
       "      <td>48750</td>\n",
       "      <td>Arlington, Virginia</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>safety end rest assured tissue produce ship</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserName  ScreenName             Location     TweetAt  \\\n",
       "0            1       44953                  NYC  02-03-2020   \n",
       "1            2       44954          Seattle, WA  02-03-2020   \n",
       "2            3       44955              unknown  02-03-2020   \n",
       "3            4       44956          Chicagoland  02-03-2020   \n",
       "4            5       44957  Melbourne, Victoria  03-03-2020   \n",
       "...        ...         ...                  ...         ...   \n",
       "3793      3794       48746            Israel ??  16-03-2020   \n",
       "3794      3795       48747       Farmington, NM  16-03-2020   \n",
       "3795      3796       48748        Haverford, PA  16-03-2020   \n",
       "3796      3797       48749              unknown  16-03-2020   \n",
       "3797      3798       48750  Arlington, Virginia  16-03-2020   \n",
       "\n",
       "                                                                                                       OriginalTweet  \\\n",
       "0                                                                new encounter empty supermarket pictured sold stock   \n",
       "1                                                                          find hand turned money pack check driving   \n",
       "2                                                                                                       find protect   \n",
       "3     panic city anxious stock food medical worker becomes confirmed patient staged event canon canon canon election   \n",
       "4                                                 news one week everyone baby milk powder next everyone toilet paper   \n",
       "...                                                                                                              ...   \n",
       "3793                                                  meanwhile supermarket people dance sing together stay positive   \n",
       "3794                                     panic buy lot non perishable echo need food also looking pack screened sure   \n",
       "3795                       prof economics talking recent research impact economy watch starting happy face confusion   \n",
       "3796                                      need instead bear assume even worst supermarket crowded like hell virus tu   \n",
       "3797                                                                     safety end rest assured tissue produce ship   \n",
       "\n",
       "     Sentiment  sentiment  \n",
       "0     Negative          0  \n",
       "1     Positive          2  \n",
       "2     Positive          2  \n",
       "3     Negative          0  \n",
       "4      Neutral          1  \n",
       "...        ...        ...  \n",
       "3793  Positive          2  \n",
       "3794  Negative          0  \n",
       "3795   Neutral          1  \n",
       "3796  Negative          0  \n",
       "3797  Positive          2  \n",
       "\n",
       "[3798 rows x 7 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "th8JB9tjC_RP"
   },
   "outputs": [],
   "source": [
    "# -- remove punctuation\n",
    "import string\n",
    "regular_punct = list(string.punctuation)\n",
    "def remove_punctuation(text):\n",
    "    for punc in regular_punct:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, ' ')\n",
    "    return text.strip()\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_punctuation)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- remove stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "def remove_stopwords(tweet):\n",
    "  tweet = tweet.split()\n",
    "  tweet = \" \".join([word for word in tweet if not word in en_stops])  \n",
    "  return tweet\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_stopwords)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "H1ts6loeC_RT"
   },
   "outputs": [],
   "source": [
    "# -- tokenize\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(word_tokenize)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "IJ6iapoCC_RU"
   },
   "outputs": [],
   "source": [
    "# -- lematize\n",
    "lem = WordNetLemmatizer()\n",
    "def lemma_wordnet(input):\n",
    "    return [lem.lemmatize(w) for w in input]\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(lemma_wordnet)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(lemma_wordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "XKrQG5dAC_RU"
   },
   "outputs": [],
   "source": [
    "# -- combine individual words\n",
    "def combine_text(input):\n",
    "    combined = ' '.join(input)\n",
    "    return combined\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(combine_text)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(combine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "v48ujX1fC_RV"
   },
   "outputs": [],
   "source": [
    "# -- Bag of words\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1, 1))\n",
    "X_train_bow = cv.fit_transform(train['OriginalTweet']) \n",
    "Y_train_bow = train['sentiment'] \n",
    "\n",
    "X_test_bow = cv.transform(test['OriginalTweet'])\n",
    "Y_test_bow = test['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Bag of words - bigrams\n",
    "\n",
    "cv_bbow = CountVectorizer(ngram_range=(2, 2))\n",
    "X_train_bbow = cv_bbow.fit_transform(train['OriginalTweet']) \n",
    "Y_train_bbow = train['sentiment']\n",
    "\n",
    "X_test_bbow = cv_bbow.transform(test['OriginalTweet']) \n",
    "Y_test_bbow = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TF-IDF\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 2, max_df = 0.8, use_idf = True, ngram_range=(1, 2))\n",
    "\n",
    "vectorizer.fit(train)\n",
    "X_train_tfidf = vectorizer.fit_transform(train['OriginalTweet'])\n",
    "Y_train_tfidf = train['sentiment'] \n",
    "\n",
    "X_test_tfidf =vectorizer.transform(test['OriginalTweet']) \n",
    "Y_test_tfidf = test['sentiment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "8NYhp501C_RV",
    "outputId": "c80277c1-6b9f-4bf4-baeb-9200a618e2c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-BoW:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(41157, 251384)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba list</th>\n",
       "      <th>abandon food</th>\n",
       "      <th>abandon need</th>\n",
       "      <th>abandon supermarket</th>\n",
       "      <th>abandon well</th>\n",
       "      <th>abandoned chilled</th>\n",
       "      <th>abandoned fate</th>\n",
       "      <th>abandoned private</th>\n",
       "      <th>abandoned shipment</th>\n",
       "      <th>abandoned shopping</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom special</th>\n",
       "      <th>zoom stock</th>\n",
       "      <th>zoom strategy</th>\n",
       "      <th>zoom toilet</th>\n",
       "      <th>zoom variety</th>\n",
       "      <th>zoom video</th>\n",
       "      <th>zoonotic deeply</th>\n",
       "      <th>zoonotic disease</th>\n",
       "      <th>zoonotic waiting</th>\n",
       "      <th>zorro saga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 251384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba list  abandon food  abandon need  abandon supermarket  abandon well  \\\n",
       "0         0             0             0                    0             0   \n",
       "1         0             0             0                    0             0   \n",
       "2         0             0             0                    0             0   \n",
       "3         0             0             0                    0             0   \n",
       "4         0             0             0                    0             0   \n",
       "\n",
       "   abandoned chilled  abandoned fate  abandoned private  abandoned shipment  \\\n",
       "0                  0               0                  0                   0   \n",
       "1                  0               0                  0                   0   \n",
       "2                  0               0                  0                   0   \n",
       "3                  0               0                  0                   0   \n",
       "4                  0               0                  0                   0   \n",
       "\n",
       "   abandoned shopping  ...  zoom special  zoom stock  zoom strategy  \\\n",
       "0                   0  ...             0           0              0   \n",
       "1                   0  ...             0           0              0   \n",
       "2                   0  ...             0           0              0   \n",
       "3                   0  ...             0           0              0   \n",
       "4                   0  ...             0           0              0   \n",
       "\n",
       "   zoom toilet  zoom variety  zoom video  zoonotic deeply  zoonotic disease  \\\n",
       "0            0             0           0                0                 0   \n",
       "1            0             0           0                0                 0   \n",
       "2            0             0           0                0                 0   \n",
       "3            0             0           0                0                 0   \n",
       "4            0             0           0                0                 0   \n",
       "\n",
       "   zoonotic waiting  zorro saga  \n",
       "0                 0           0  \n",
       "1                 0           0  \n",
       "2                 0           0  \n",
       "3                 0           0  \n",
       "4                 0           0  \n",
       "\n",
       "[5 rows x 251384 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"B-BoW:\", X_train_bbow.shape)\n",
    "df_bbow = pd.DataFrame(X_train_bbow.toarray(), columns=cv_bbow.get_feature_names())\n",
    "display(df_bbow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.65755588 0.64856657 0.64390718 0.64050541 0.63868303]\n",
      "0.6458436126242504\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.65767736 0.64880952 0.64402867 0.64086988 0.63941198]\n",
      "0.6461594827632009\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.67237609 0.66399417 0.66128052 0.66200948 0.66128052]\n",
      "0.6641881576901374\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.67589893 0.66873178 0.66735512 0.67209331 0.67099988]\n",
      "0.6710158029228666\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.66800292 0.66265792 0.6586077  0.66516827 0.67014944]\n",
      "0.6649172479447026\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.64917396 0.64856657 0.6420848  0.65058924 0.65447698]\n",
      "0.6489783078477759\n",
      "\n",
      "\n",
      "0.6671932596103213\n",
      "precision: [0.74764595 0.60606061 0.60911602]\n",
      "recall: [0.72933252 0.03231018 0.85575679]\n",
      "fscore: [0.7383757  0.06134969 0.71167294]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with bag of word\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_bow, Y_train_bow, cv=5)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "    \n",
    "mnb.fit(X_train_bow, Y_train_bow)\n",
    "print(mnb.score(X_test_bow, Y_test_bow))\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_bow, mnb.predict(X_test_bow))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "id": "z7c9aFuVC_RW",
    "outputId": "509a7016-9525-4449-af87-8e97ac9e9266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.55344995 0.55709427 0.53838678 0.54373178 0.5505345  0.55126336\n",
      " 0.5281827  0.55407047 0.56330498 0.53511543]\n",
      "0.5475134230050291\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.53838678 0.53595724 0.5223518  0.5250243  0.5308552  0.52405248\n",
      " 0.50680272 0.52952612 0.53948967 0.51543135]\n",
      "0.5267877659656119\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.42274052 0.4159378  0.41399417 0.41763848 0.40014577 0.41350826\n",
      " 0.39844509 0.40583232 0.40121507 0.39149453]\n",
      "0.4080952026705492\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.51676385 0.49514091 0.50680272 0.49246842 0.48347911 0.48688047\n",
      " 0.48809524 0.48894289 0.49064399 0.47752126]\n",
      "0.4926738850374379\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.54713314 0.53061224 0.54081633 0.52721088 0.51603499 0.52113703\n",
      " 0.51773567 0.52660996 0.52077764 0.509113  ]\n",
      "0.5257180879642258\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.56827017 0.5563654  0.55466472 0.55247813 0.53644315 0.53765792\n",
      " 0.54737609 0.55674362 0.56087485 0.54119077]\n",
      "0.5512064822457363\n",
      "\n",
      "\n",
      "0.5518694049499737\n",
      "precision: [0.64764079 0.71428571 0.50060557]\n",
      "recall: [0.52112676 0.00807754 0.80206986]\n",
      "fscore: [0.57753648 0.01597444 0.61645538]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with bigram bag of word\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_bbow, Y_train_bbow, cv=10)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "\n",
    "mnb.fit(X_train_bbow, Y_train_bbow)\n",
    "print(mnb.score(X_test_bbow, Y_test_bbow))\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_bbow, mnb.predict(X_test_bbow))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "#accuracy_score(mnb.predict(X_test_bbow), Y_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "id": "C4B0It9ZC_RW",
    "outputId": "bc355275-2945-49b7-bb14-a470f33c7569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  175.0\n",
      "[0.44995141 0.45602527 0.45578231 0.45602527 0.452138   0.44922255\n",
      " 0.45238095 0.44617254 0.44422843 0.44690158]\n",
      "0.45088283047987465\n",
      "\n",
      "\n",
      "alpha:  200.0\n",
      "[0.44630709 0.45238095 0.45068027 0.44897959 0.44727891 0.44630709\n",
      " 0.44727891 0.44325638 0.44325638 0.44520049]\n",
      "0.4470926072216771\n",
      "\n",
      "\n",
      "alpha:  225.0\n",
      "[0.44314869 0.44655005 0.446793   0.44655005 0.44412051 0.44484937\n",
      " 0.44460641 0.4417983  0.44204131 0.44252734]\n",
      "0.44429850259840087\n",
      "\n",
      "\n",
      "alpha:  250.0\n",
      "[0.44314869 0.44484937 0.44412051 0.44460641 0.44169096 0.44290573\n",
      " 0.44241983 0.44082625 0.44155529 0.44034022]\n",
      "0.4426463246294873\n",
      "\n",
      "\n",
      "alpha:  300.0\n",
      "[0.44120505 0.44217687 0.44217687 0.44193392 0.44047619 0.43999028\n",
      " 0.43974733 0.43888214 0.44034022 0.43985419]\n",
      "0.4406783060386106\n",
      "\n",
      "\n",
      "0.6350710900473934\n",
      "precision: [0.74089636 0.63636364 0.57100466]\n",
      "recall: [0.64788732 0.01130856 0.87128072]\n",
      "fscore: [0.69127736 0.02222222 0.68988476]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with TF-IDF\n",
    "alpha = [175.0, 200.0, 225.0, 250.0, 300.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_tfidf, Y_train_tfidf, cv=10)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, Y_train_tfidf)\n",
    "print(mnb.score(X_test_tfidf, Y_test_tfidf))\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_tfidf, mnb.predict(X_test_tfidf))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "p0O4c1bVC_RZ"
   },
   "outputs": [],
   "source": [
    "# -- decision tree classifier with BoW\n",
    "dtclassifier=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None)\n",
    "score=cross_val_score(dtclassifier, X_train_bow, Y_train_bow, cv=10)\n",
    "dtclassifier.fit(X_train_bow, Y_train_bow)\n",
    "preddt = dtclassifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_para = {'criterion':['gini','entropy']}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=None), tree_para, cv=10)\n",
    "clf.fit(X_train_bow, Y_train_bow)\n",
    "preddt = dtclassifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "O6sZIkRCC_RZ",
    "outputId": "d7a6c598-e06c-4d6f-d694-17af5d0c26c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6545550289626119\n",
      "precision: [0.68603043 0.55375552 0.66826061]\n",
      "recall: [0.60747091 0.60743134 0.72315653]\n",
      "fscore: [0.64436505 0.57935285 0.69462566]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_bow)\n",
    "print(accuracy)\n",
    "#print(score.mean())\n",
    "# unigram: .69\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_bbow, preddt)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- decision tree classifier with B-BoW\n",
    "tree_para = {'criterion':['gini','entropy']}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=None), tree_para, cv=10)\n",
    "clf.fit(X_train_bbow, Y_train_bbow)\n",
    "preddt = clf.predict(X_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_bbow)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_bbow, preddt)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2t4tRpGC_Ra"
   },
   "outputs": [],
   "source": [
    "# -- decision tree classifier with tf-idf\n",
    "tree_para = {'criterion':['gini','entropy']}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=None), tree_para, cv=10)\n",
    "clf.fit(X_train_tfidf,Y_train_tfidf)\n",
    "preddt = clf.predict(X_test_tfidf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ecSbdERC_Ra",
    "outputId": "cd48ef80-cf60-4b51-d19f-e32eb15f514d"
   },
   "outputs": [],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_tfidf)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_tfidf, preddt)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "3SQdF6eqC_Rb",
    "outputId": "f4e9fdda-9853-4141-fb94-3099fc06f3d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVC(kernel=linear)\n",
      "Training time: 584.530156s; Prediction time: 6.890333s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1157, 3798]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-cc4910968181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results for SVC(kernel=linear)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time: %fs; Prediction time: %fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_linear_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_linear_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positive: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negative: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \"\"\"\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1157, 3798]"
     ]
    }
   ],
   "source": [
    "# -- SVM, kernel=linear - BoW\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(X_train_bow, Y_train_bow)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(X_test_bow)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "# results\n",
    "print(\"Results for SVC(kernel=linear)\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = classification_report(Y_test_bow, prediction_linear, output_dict=True)\n",
    "print('positive: ', report['Positive'])\n",
    "print('negative: ', report['Negative'])\n",
    "print('notr: ', report['Neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy= accuracy_score(prediction_linear,Y_test_bow)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gHmw2XNC_Rb",
    "outputId": "4065b3bf-7844-418e-fc30-41dc0463aa52"
   },
   "outputs": [],
   "source": [
    "review = \"\"\"give elderly disabled shopping amid outbreak\"\"\"\n",
    "review_vector = vectorizer.transform([review]) # vectorizing\n",
    "print(classifier_linear.predict(review_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "id": "6k6epXw-C_Rb",
    "outputId": "0e283bf4-085d-40da-d89d-544064f67b7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -- logistic regression with hashing \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class=\"ovr\")\n",
    "log_reg.fit(X_train_bbow, X_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11239x228214 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 181700 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_bbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "id": "3SKYyCzjC_Rc",
    "outputId": "6c3fab93-a275-427f-e550-428fecad07e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7882373876679419"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy = log_reg.score(X_train_bbow, Y_train_bbow)\n",
    "test_accuracy = log_reg.score(X_test_bbow, Y_test_bbow)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "lne6gnDCC_Rc",
    "outputId": "6243e866-48f7-421c-ca6c-5417f3401400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial (Softmax)\n",
      "--------------------\n",
      "Accuracy on Train Data : 0.83\n",
      "Accuracy on Test Data  : 0.78\n"
     ]
    }
   ],
   "source": [
    "log_reg_mnm = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "log_reg_mnm.fit(X_train_hash, X_test_hash)\n",
    "\n",
    "train_accuracy = log_reg_mnm.score(X_train_hash, X_test_hash)\n",
    "test_accuracy = log_reg_mnm.score(Y_train_hash, Y_test)\n",
    "\n",
    "print('Multinomial (Softmax)', '-'*20, \n",
    "      'Accuracy on Train Data : {:.2f}'.format(train_accuracy), \n",
    "      'Accuracy on Test Data  : {:.2f}'.format(test_accuracy), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "fVDYoV1DC_Rc",
    "outputId": "afd36e64-3249-4fed-ba18-bc1c7e8de377"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_values</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.476361</td>\n",
       "      <td>0.479224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.590728</td>\n",
       "      <td>0.584216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.719213</td>\n",
       "      <td>0.697482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.829962</td>\n",
       "      <td>0.775514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.868668</td>\n",
       "      <td>0.783522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.874184</td>\n",
       "      <td>0.774980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.874659</td>\n",
       "      <td>0.773200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_values  Train Accuracy  Test Accuracy\n",
       "0     0.001        0.476361       0.479224\n",
       "1     0.010        0.590728       0.584216\n",
       "2     0.100        0.719213       0.697482\n",
       "3     1.000        0.829962       0.775514\n",
       "4    10.000        0.868668       0.783522\n",
       "5   100.000        0.874184       0.774980\n",
       "6  1000.000        0.874659       0.773200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- validation for multinomial log reg \n",
    "C_values = [0.001,0.01, 0.1,1,10,100, 1000]\n",
    "\n",
    "accuracy_values = pd.DataFrame(columns=['C_values', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "for c in C_values:\n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(penalty = 'l2', C = c, random_state = 0, solver='lbfgs', multi_class='multinomial')\n",
    "    lr.fit(X_train_hash, X_test_hash)\n",
    "    accuracy_values = accuracy_values.append({'C_values': c,\n",
    "                                              'Train Accuracy': lr.score(X_train_hash, X_test_hash),\n",
    "                                              'Test Accuracy': lr.score(Y_train_hash, Y_test)\n",
    "                                             }, ignore_index=True)\n",
    "display(accuracy_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJbMApy1C_Rc"
   },
   "outputs": [],
   "source": [
    "# -- grid search\n",
    "parameters = {\"C\": [10 ** x for x in range (-5, 5, 1)],\n",
    "              \"penalty\": ['l1', 'l2']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plzyULwvC_Rc",
    "outputId": "39121d6c-46ca-4aeb-c2a5-23264363b5b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(multi_class='ovr'),\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000, 10000],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_cv = GridSearchCV(estimator=log_reg,\n",
    "                       param_grid = parameters,\n",
    "                       cv = 10\n",
    "                      )\n",
    "\n",
    "grid_cv.fit(X_train_hash, X_test_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvYh6Su_C_Rd",
    "outputId": "e3657790-b054-46ec-8b5c-3ee8c62c9969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters :  {'C': 10, 'penalty': 'l2'}\n",
      "Best Score      :  0.8185134316740406\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters : \", grid_cv.best_params_)\n",
    "print(\"Best Score      : \", grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDnHvC_AC_Rd",
    "outputId": "f8289337-6d4d-4f38-a56a-74322e3f0866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 11.2 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.313961</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l2'}</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437152</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.190604</td>\n",
       "      <td>0.081269</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437259</td>\n",
       "      <td>0.437152</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.347032</td>\n",
       "      <td>0.042141</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.438019</td>\n",
       "      <td>0.439798</td>\n",
       "      <td>0.438909</td>\n",
       "      <td>0.438019</td>\n",
       "      <td>0.438909</td>\n",
       "      <td>0.439502</td>\n",
       "      <td>0.439632</td>\n",
       "      <td>0.439929</td>\n",
       "      <td>0.439039</td>\n",
       "      <td>0.439632</td>\n",
       "      <td>0.439139</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.741687</td>\n",
       "      <td>0.069908</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>0.575030</td>\n",
       "      <td>0.559312</td>\n",
       "      <td>0.567023</td>\n",
       "      <td>0.551008</td>\n",
       "      <td>0.570285</td>\n",
       "      <td>0.564947</td>\n",
       "      <td>0.557995</td>\n",
       "      <td>0.563631</td>\n",
       "      <td>0.564818</td>\n",
       "      <td>0.555918</td>\n",
       "      <td>0.562997</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.001108</td>\n",
       "      <td>0.650369</td>\n",
       "      <td>0.011164</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.684164</td>\n",
       "      <td>0.673488</td>\n",
       "      <td>0.678826</td>\n",
       "      <td>0.653025</td>\n",
       "      <td>0.682681</td>\n",
       "      <td>0.668743</td>\n",
       "      <td>0.674281</td>\n",
       "      <td>0.680510</td>\n",
       "      <td>0.673984</td>\n",
       "      <td>0.659745</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38.848168</td>\n",
       "      <td>2.187563</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.784401</td>\n",
       "      <td>0.776394</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.762159</td>\n",
       "      <td>0.784994</td>\n",
       "      <td>0.770463</td>\n",
       "      <td>0.773658</td>\n",
       "      <td>0.775734</td>\n",
       "      <td>0.785227</td>\n",
       "      <td>0.762978</td>\n",
       "      <td>0.774321</td>\n",
       "      <td>0.008267</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>41.995080</td>\n",
       "      <td>0.480354</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.827699</td>\n",
       "      <td>0.814650</td>\n",
       "      <td>0.810202</td>\n",
       "      <td>0.814353</td>\n",
       "      <td>0.826216</td>\n",
       "      <td>0.819098</td>\n",
       "      <td>0.819045</td>\n",
       "      <td>0.815188</td>\n",
       "      <td>0.823791</td>\n",
       "      <td>0.814892</td>\n",
       "      <td>0.818513</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 100, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>41.145590</td>\n",
       "      <td>0.834779</td>\n",
       "      <td>0.013074</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "      <td>0.816726</td>\n",
       "      <td>0.797450</td>\n",
       "      <td>0.803974</td>\n",
       "      <td>0.808126</td>\n",
       "      <td>0.820285</td>\n",
       "      <td>0.811388</td>\n",
       "      <td>0.815485</td>\n",
       "      <td>0.812519</td>\n",
       "      <td>0.819341</td>\n",
       "      <td>0.818155</td>\n",
       "      <td>0.812345</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41.099051</td>\n",
       "      <td>0.950770</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l2'}</td>\n",
       "      <td>0.801601</td>\n",
       "      <td>0.792705</td>\n",
       "      <td>0.797746</td>\n",
       "      <td>0.793298</td>\n",
       "      <td>0.804567</td>\n",
       "      <td>0.801008</td>\n",
       "      <td>0.798576</td>\n",
       "      <td>0.798279</td>\n",
       "      <td>0.803916</td>\n",
       "      <td>0.808662</td>\n",
       "      <td>0.800036</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10000, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40.524569</td>\n",
       "      <td>0.326188</td>\n",
       "      <td>0.011391</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>10000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10000, 'penalty': 'l2'}</td>\n",
       "      <td>0.800119</td>\n",
       "      <td>0.790629</td>\n",
       "      <td>0.793001</td>\n",
       "      <td>0.780546</td>\n",
       "      <td>0.808719</td>\n",
       "      <td>0.793891</td>\n",
       "      <td>0.795313</td>\n",
       "      <td>0.795313</td>\n",
       "      <td>0.797983</td>\n",
       "      <td>0.798576</td>\n",
       "      <td>0.795409</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.002367      0.000275         0.000000        0.000000   1e-05   \n",
       "1        3.313961      0.044434         0.010587        0.000077   1e-05   \n",
       "2        0.002228      0.000192         0.000000        0.000000  0.0001   \n",
       "3        3.190604      0.081269         0.011091        0.001986  0.0001   \n",
       "4        0.002420      0.000151         0.000000        0.000000   0.001   \n",
       "5        3.347032      0.042141         0.011306        0.002212   0.001   \n",
       "6        0.002300      0.000184         0.000000        0.000000    0.01   \n",
       "7        6.741687      0.069908         0.011410        0.002420    0.01   \n",
       "8        0.002367      0.000176         0.000000        0.000000     0.1   \n",
       "9       17.001108      0.650369         0.011164        0.001499     0.1   \n",
       "10       0.002403      0.000193         0.000000        0.000000       1   \n",
       "11      38.848168      2.187563         0.010815        0.000472       1   \n",
       "12       0.002316      0.000240         0.000000        0.000000      10   \n",
       "13      41.995080      0.480354         0.010693        0.000114      10   \n",
       "14       0.002336      0.000187         0.000000        0.000000     100   \n",
       "15      41.145590      0.834779         0.013074        0.007048     100   \n",
       "16       0.002140      0.000289         0.000000        0.000000    1000   \n",
       "17      41.099051      0.950770         0.010516        0.000163    1000   \n",
       "18       0.002234      0.000265         0.000000        0.000000   10000   \n",
       "19      40.524569      0.326188         0.011391        0.002111   10000   \n",
       "\n",
       "   param_penalty                          params  split0_test_score  \\\n",
       "0             l1   {'C': 1e-05, 'penalty': 'l1'}                NaN   \n",
       "1             l2   {'C': 1e-05, 'penalty': 'l2'}           0.437129   \n",
       "2             l1  {'C': 0.0001, 'penalty': 'l1'}                NaN   \n",
       "3             l2  {'C': 0.0001, 'penalty': 'l2'}           0.437129   \n",
       "4             l1   {'C': 0.001, 'penalty': 'l1'}                NaN   \n",
       "5             l2   {'C': 0.001, 'penalty': 'l2'}           0.438019   \n",
       "6             l1    {'C': 0.01, 'penalty': 'l1'}                NaN   \n",
       "7             l2    {'C': 0.01, 'penalty': 'l2'}           0.575030   \n",
       "8             l1     {'C': 0.1, 'penalty': 'l1'}                NaN   \n",
       "9             l2     {'C': 0.1, 'penalty': 'l2'}           0.684164   \n",
       "10            l1       {'C': 1, 'penalty': 'l1'}                NaN   \n",
       "11            l2       {'C': 1, 'penalty': 'l2'}           0.784401   \n",
       "12            l1      {'C': 10, 'penalty': 'l1'}                NaN   \n",
       "13            l2      {'C': 10, 'penalty': 'l2'}           0.827699   \n",
       "14            l1     {'C': 100, 'penalty': 'l1'}                NaN   \n",
       "15            l2     {'C': 100, 'penalty': 'l2'}           0.816726   \n",
       "16            l1    {'C': 1000, 'penalty': 'l1'}                NaN   \n",
       "17            l2    {'C': 1000, 'penalty': 'l2'}           0.801601   \n",
       "18            l1   {'C': 10000, 'penalty': 'l1'}                NaN   \n",
       "19            l2   {'C': 10000, 'penalty': 'l2'}           0.800119   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.436833           0.437129           0.437129   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.436833           0.437129           0.437129   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.439798           0.438909           0.438019   \n",
       "6                 NaN                NaN                NaN   \n",
       "7            0.559312           0.567023           0.551008   \n",
       "8                 NaN                NaN                NaN   \n",
       "9            0.673488           0.678826           0.653025   \n",
       "10                NaN                NaN                NaN   \n",
       "11           0.776394           0.767200           0.762159   \n",
       "12                NaN                NaN                NaN   \n",
       "13           0.814650           0.810202           0.814353   \n",
       "14                NaN                NaN                NaN   \n",
       "15           0.797450           0.803974           0.808126   \n",
       "16                NaN                NaN                NaN   \n",
       "17           0.792705           0.797746           0.793298   \n",
       "18                NaN                NaN                NaN   \n",
       "19           0.790629           0.793001           0.780546   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.437129           0.437129           0.437259   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.437129           0.437129           0.437259   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.438909           0.439502           0.439632   \n",
       "6                 NaN                NaN                NaN   \n",
       "7            0.570285           0.564947           0.557995   \n",
       "8                 NaN                NaN                NaN   \n",
       "9            0.682681           0.668743           0.674281   \n",
       "10                NaN                NaN                NaN   \n",
       "11           0.784994           0.770463           0.773658   \n",
       "12                NaN                NaN                NaN   \n",
       "13           0.826216           0.819098           0.819045   \n",
       "14                NaN                NaN                NaN   \n",
       "15           0.820285           0.811388           0.815485   \n",
       "16                NaN                NaN                NaN   \n",
       "17           0.804567           0.801008           0.798576   \n",
       "18                NaN                NaN                NaN   \n",
       "19           0.808719           0.793891           0.795313   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0                 NaN                NaN                NaN              NaN   \n",
       "1            0.437259           0.437259           0.437259         0.437152   \n",
       "2                 NaN                NaN                NaN              NaN   \n",
       "3            0.437259           0.437259           0.437259         0.437152   \n",
       "4                 NaN                NaN                NaN              NaN   \n",
       "5            0.439929           0.439039           0.439632         0.439139   \n",
       "6                 NaN                NaN                NaN              NaN   \n",
       "7            0.563631           0.564818           0.555918         0.562997   \n",
       "8                 NaN                NaN                NaN              NaN   \n",
       "9            0.680510           0.673984           0.659745         0.672944   \n",
       "10                NaN                NaN                NaN              NaN   \n",
       "11           0.775734           0.785227           0.762978         0.774321   \n",
       "12                NaN                NaN                NaN              NaN   \n",
       "13           0.815188           0.823791           0.814892         0.818513   \n",
       "14                NaN                NaN                NaN              NaN   \n",
       "15           0.812519           0.819341           0.818155         0.812345   \n",
       "16                NaN                NaN                NaN              NaN   \n",
       "17           0.798279           0.803916           0.808662         0.800036   \n",
       "18                NaN                NaN                NaN              NaN   \n",
       "19           0.795313           0.797983           0.798576         0.795409   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0              NaN               20  \n",
       "1         0.000123                9  \n",
       "2              NaN               18  \n",
       "3         0.000123                9  \n",
       "4              NaN               15  \n",
       "5         0.000656                8  \n",
       "6              NaN               11  \n",
       "7         0.006738                7  \n",
       "8              NaN               12  \n",
       "9         0.009510                6  \n",
       "10             NaN               14  \n",
       "11        0.008267                5  \n",
       "12             NaN               16  \n",
       "13        0.005456                1  \n",
       "14             NaN               17  \n",
       "15        0.006968                2  \n",
       "16             NaN               19  \n",
       "17        0.004722                3  \n",
       "18             NaN               13  \n",
       "19        0.006840                4  "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   mean_fit_time      20 non-null     float64\n",
      " 1   std_fit_time       20 non-null     float64\n",
      " 2   mean_score_time    20 non-null     float64\n",
      " 3   std_score_time     20 non-null     float64\n",
      " 4   param_C            20 non-null     object \n",
      " 5   param_penalty      20 non-null     object \n",
      " 6   params             20 non-null     object \n",
      " 7   split0_test_score  10 non-null     float64\n",
      " 8   split1_test_score  10 non-null     float64\n",
      " 9   split2_test_score  10 non-null     float64\n",
      " 10  split3_test_score  10 non-null     float64\n",
      " 11  split4_test_score  10 non-null     float64\n",
      " 12  split5_test_score  10 non-null     float64\n",
      " 13  split6_test_score  10 non-null     float64\n",
      " 14  split7_test_score  10 non-null     float64\n",
      " 15  split8_test_score  10 non-null     float64\n",
      " 16  split9_test_score  10 non-null     float64\n",
      " 17  mean_test_score    10 non-null     float64\n",
      " 18  std_test_score     10 non-null     float64\n",
      " 19  rank_test_score    20 non-null     int32  \n",
      "dtypes: float64(16), int32(1), object(3)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time results = grid_cv.cv_results_\n",
    "\n",
    "df1 = pd.DataFrame(results)\n",
    "display(df1.head(35))\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbswP-9vC_Rd",
    "outputId": "38d95613-e68f-4e54-f948-512f42c4b986"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.818513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>l2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.812345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.800036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>l2</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.795409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.672944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.439139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.437152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.437152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>l1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>l1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>l1</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>l1</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_penalty param_C  mean_test_score\n",
       "13            l2      10         0.818513\n",
       "15            l2     100         0.812345\n",
       "17            l2    1000         0.800036\n",
       "19            l2   10000         0.795409\n",
       "11            l2       1         0.774321\n",
       "9             l2     0.1         0.672944\n",
       "7             l2    0.01         0.562997\n",
       "5             l2   0.001         0.439139\n",
       "1             l2   1e-05         0.437152\n",
       "3             l2  0.0001         0.437152\n",
       "0             l1   1e-05              NaN\n",
       "2             l1  0.0001              NaN\n",
       "4             l1   0.001              NaN\n",
       "6             l1    0.01              NaN\n",
       "8             l1     0.1              NaN\n",
       "10            l1       1              NaN\n",
       "12            l1      10              NaN\n",
       "14            l1     100              NaN\n",
       "16            l1    1000              NaN\n",
       "18            l1   10000              NaN"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1[['param_penalty','param_C', 'mean_test_score']]\n",
    "df1 = df1.sort_values(by='mean_test_score', ascending = False)\n",
    "df1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "covid19-tweets-sentiment-analysis-nlp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 3889.575075,
   "end_time": "2021-02-14T13:29:29.031663",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-14T12:24:39.456588",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
