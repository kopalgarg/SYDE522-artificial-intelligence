{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sF1azMHDC_Q-"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yk2ky07-C_RA"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score,  accuracy_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score,  accuracy_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "D50G4l0SC_RA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7aht-HZC_RB",
    "outputId": "da9b097a-0900-4f8f-b500-c35f03c33381"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWGibQmRC_RB",
    "outputId": "862c812c-d2b5-443c-e35e-dc5daf2fba70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emot in /Users/kgarg/opt/anaconda3/lib/python3.8/site-packages (2.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbOpjZOUKz40",
    "outputId": "355a85bf-91de-46f2-eb9e-3bc5bf3c49be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in /Users/kgarg/opt/anaconda3/lib/python3.8/site-packages (0.6.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9AVjkrtaC_RC"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473506"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OriginalTweet'].str.lower().str.split().apply(len).sum()\n",
    "pd.options.display.max_colwidth=200\n",
    "df['OriginalTweet'][3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KYGb9A4IC_RC"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/Corona_NLP_train.csv', encoding=\"ISO-8859-1\", low_memory=False)\n",
    "test = pd.read_csv('./data/Corona_NLP_test.csv', encoding=\"ISO-8859-1\", low_memory=False) \n",
    "#df = train.append(test, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jw9JFgGgC_RE"
   },
   "outputs": [],
   "source": [
    "# -- filling missing values\n",
    "train['Location'].fillna(value='unknown', inplace=True) \n",
    "test['Location'].fillna(value='unknown', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vE-GHkyGC_RE"
   },
   "outputs": [],
   "source": [
    "# -- label encoding \n",
    "encoding = {'Extremely Negative': 'Negative',\n",
    "            'Extremely Positive': 'Positive'\n",
    "           }\n",
    "labels = ['Negative', 'Positive']\n",
    "train['Sentiment'].replace(encoding, inplace=True)\n",
    "train[\"sentiment\"] = LabelEncoder().fit_transform(train[\"Sentiment\"])\n",
    "\n",
    "test['Sentiment'].replace(encoding, inplace=True)\n",
    "test[\"sentiment\"] = LabelEncoder().fit_transform(test[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3MKNdTFCC_RG"
   },
   "outputs": [],
   "source": [
    "# -- remove URLs\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# -- remove HTML\n",
    "def html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_urls)\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(html)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(remove_urls)\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UXbuAXvlC_RH"
   },
   "outputs": [],
   "source": [
    "# -- lowercase\n",
    "train['OriginalTweet'] = train['OriginalTweet'].str.lower()\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "n3RgoyTKC_RH"
   },
   "outputs": [],
   "source": [
    "# -- convert emojis and emoticons to words\n",
    "def convert_emojis_emoticons(text):\n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(convert_emojis_emoticons)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(convert_emojis_emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qwibfPcyC_RO"
   },
   "outputs": [],
   "source": [
    "# -- remove special and non-ASCII characters\n",
    "def clean(tweet): \n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â²\", \"\", tweet)\n",
    "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â¹\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â½\", \"\", tweet)\n",
    "    tweet = re.sub(r\"â¾\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼berweist\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼cretsiz\", \"\", tweet)\n",
    "    tweet = re.sub(r\"zã¼rich\", \"\", tweet)\n",
    "    tweet = re.sub(r\"ã¼retime\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "    tweet = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'mentioned', tweet)\n",
    "    tweet = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'referance', tweet)\n",
    "    tweet = re.sub(r'£|\\$', 'money', tweet)\n",
    "    tweet = re.sub(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b', ' ', tweet)\n",
    "    tweet = re.sub(r'\\d+(\\.\\d+)?', ' ', tweet) \n",
    "    tweet = re.sub(r'[^\\w\\d\\s]', ' ', tweet)\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    tweet = re.sub(r'^\\s+|\\s+?$', '', tweet.lower())\n",
    "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
    "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
    "    tweet = re.sub(r\"&amp;\", \"&\", tweet) \n",
    "    tweet = re.sub(r\"_\", \"  \", tweet)\n",
    "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
    "    for p in punctuations:\n",
    "        tweet = tweet.replace(p, f' {p} ')\n",
    "    return str(tweet)\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(clean)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "QWAIdXXiX7R3"
   },
   "outputs": [],
   "source": [
    "# -- spellcheck and keep words that are in the English dictionary\n",
    "spell = SpellChecker(distance = 1, language='en')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else: \n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "def ensure_english(text):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(text) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(correct_spellings)\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(ensure_english)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(correct_spellings)\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(ensure_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "th8JB9tjC_RP"
   },
   "outputs": [],
   "source": [
    "# -- remove punctuation\n",
    "import string\n",
    "regular_punct = list(string.punctuation)\n",
    "def remove_punctuation(text):\n",
    "    for punc in regular_punct:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, ' ')\n",
    "    return text.strip()\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_punctuation)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- remove stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "def remove_stopwords(tweet):\n",
    "  tweet = tweet.split()\n",
    "  tweet = \" \".join([word for word in tweet if not word in en_stops])  \n",
    "  return tweet\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_stopwords)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "H1ts6loeC_RT"
   },
   "outputs": [],
   "source": [
    "# -- tokenize\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(word_tokenize)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IJ6iapoCC_RU"
   },
   "outputs": [],
   "source": [
    "# -- lematize\n",
    "lem = WordNetLemmatizer()\n",
    "def lemma_wordnet(input):\n",
    "    return [lem.lemmatize(w) for w in input]\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(lemma_wordnet)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(lemma_wordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XKrQG5dAC_RU"
   },
   "outputs": [],
   "source": [
    "# -- combine individual words\n",
    "def combine_text(input):\n",
    "    combined = ' '.join(input)\n",
    "    return combined\n",
    "\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(combine_text)\n",
    "\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(combine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "v48ujX1fC_RV"
   },
   "outputs": [],
   "source": [
    "# -- Bag of words\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1, 1))\n",
    "X_train_bow = cv.fit_transform(train['OriginalTweet']) \n",
    "Y_train_bow = train['sentiment'] \n",
    "\n",
    "X_test_bow = cv.transform(test['OriginalTweet'])\n",
    "Y_test_bow = test['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Bag of words - bigrams\n",
    "\n",
    "cv_bbow = CountVectorizer(ngram_range=(2, 2))\n",
    "X_train_bbow = cv_bbow.fit_transform(train['OriginalTweet']) \n",
    "Y_train_bbow = train['sentiment']\n",
    "\n",
    "X_test_bbow = cv_bbow.transform(test['OriginalTweet']) \n",
    "Y_test_bbow = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TF-IDF\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 2, max_df = 0.8, use_idf = True, ngram_range=(1, 1))\n",
    "\n",
    "vectorizer.fit(train)\n",
    "X_train_tfidf = vectorizer.fit_transform(train['OriginalTweet'])\n",
    "Y_train_tfidf = train['sentiment'] \n",
    "\n",
    "X_test_tfidf =vectorizer.transform(test['OriginalTweet']) \n",
    "Y_test_tfidf = test['sentiment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "8NYhp501C_RV",
    "outputId": "c80277c1-6b9f-4bf4-baeb-9200a618e2c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-BoW:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(41157, 387999)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa baker</th>\n",
       "      <th>aa cristobal</th>\n",
       "      <th>aaa covid</th>\n",
       "      <th>aaa gas</th>\n",
       "      <th>aaa low</th>\n",
       "      <th>aaa official</th>\n",
       "      <th>aaa say</th>\n",
       "      <th>aaa texas</th>\n",
       "      <th>aaaaas commission</th>\n",
       "      <th>aaaand toilet</th>\n",
       "      <th>...</th>\n",
       "      <th>âmoney worth</th>\n",
       "      <th>âmoney would</th>\n",
       "      <th>âmoney wow</th>\n",
       "      <th>âmoney yes</th>\n",
       "      <th>âmoney yorkshire</th>\n",
       "      <th>âmoney âmoney</th>\n",
       "      <th>âmoneycashtag chance</th>\n",
       "      <th>âmoneyxx offer</th>\n",
       "      <th>ãmoneyo contra</th>\n",
       "      <th>ãmoneyo precaucao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 387999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa baker  aa cristobal  aaa covid  aaa gas  aaa low  aaa official  aaa say  \\\n",
       "0         0             0          0        0        0             0        0   \n",
       "1         0             0          0        0        0             0        0   \n",
       "2         0             0          0        0        0             0        0   \n",
       "3         0             0          0        0        0             0        0   \n",
       "4         0             0          0        0        0             0        0   \n",
       "\n",
       "   aaa texas  aaaaas commission  aaaand toilet  ...  âmoney worth  \\\n",
       "0          0                  0              0  ...             0   \n",
       "1          0                  0              0  ...             0   \n",
       "2          0                  0              0  ...             0   \n",
       "3          0                  0              0  ...             0   \n",
       "4          0                  0              0  ...             0   \n",
       "\n",
       "   âmoney would  âmoney wow  âmoney yes  âmoney yorkshire  âmoney âmoney  \\\n",
       "0             0           0           0                 0              0   \n",
       "1             0           0           0                 0              0   \n",
       "2             0           0           0                 0              0   \n",
       "3             0           0           0                 0              0   \n",
       "4             0           0           0                 0              0   \n",
       "\n",
       "   âmoneycashtag chance  âmoneyxx offer  ãmoneyo contra  ãmoneyo precaucao  \n",
       "0                     0               0               0                  0  \n",
       "1                     0               0               0                  0  \n",
       "2                     0               0               0                  0  \n",
       "3                     0               0               0                  0  \n",
       "4                     0               0               0                  0  \n",
       "\n",
       "[5 rows x 387999 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"B-BoW:\", X_train_bbow.shape)\n",
    "df_bbow = pd.DataFrame(X_train_bbow.toarray(), columns=cv_bbow.get_feature_names())\n",
    "display(df_bbow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.65755588 0.64856657 0.64390718 0.64050541 0.63868303]\n",
      "0.6458436126242504\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.65767736 0.64880952 0.64402867 0.64086988 0.63941198]\n",
      "0.6461594827632009\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.67237609 0.66399417 0.66128052 0.66200948 0.66128052]\n",
      "0.6641881576901374\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.67589893 0.66873178 0.66735512 0.67209331 0.67099988]\n",
      "0.6710158029228666\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.66800292 0.66265792 0.6586077  0.66516827 0.67014944]\n",
      "0.6649172479447026\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.64917396 0.64856657 0.6420848  0.65058924 0.65447698]\n",
      "0.6489783078477759\n",
      "\n",
      "\n",
      "0.6671932596103213\n",
      "precision: [0.74764595 0.60606061 0.60911602]\n",
      "recall: [0.72933252 0.03231018 0.85575679]\n",
      "fscore: [0.7383757  0.06134969 0.71167294]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with bag of word\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_bow, Y_train_bow, cv=5)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "\n",
    "mnb = MultinomialNB(alpha = 1)\n",
    "mnb.fit(X_train_bow, Y_train_bow)\n",
    "print(mnb.score(X_test_bow, Y_test_bow))\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_bow, mnb.predict(X_test_bow))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "z7c9aFuVC_RW",
    "outputId": "509a7016-9525-4449-af87-8e97ac9e9266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.55272109 0.56632653 0.53814383 0.55199223 0.55417881 0.5617104\n",
      " 0.53911565 0.55674362 0.5671932  0.55893074]\n",
      "0.5547056090271554\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.53790087 0.54591837 0.52380952 0.53328474 0.53206997 0.54081633\n",
      " 0.51797862 0.5399757  0.54313487 0.53341434]\n",
      "0.5348303334525963\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.44047619 0.42614189 0.43634597 0.43707483 0.4154519  0.42031098\n",
      " 0.40913508 0.41652491 0.41919806 0.40413123]\n",
      "0.4224791023856166\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.54446064 0.52988338 0.53279883 0.53401361 0.51627794 0.53911565\n",
      " 0.51044704 0.52466586 0.51980559 0.51154313]\n",
      "0.5263011665350048\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.57798834 0.55344995 0.55442177 0.56073858 0.5451895  0.57458698\n",
      " 0.55272109 0.5582017  0.55893074 0.54556501]\n",
      "0.5581793658272196\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.57555879 0.56997085 0.5675413  0.58114674 0.55466472 0.58041788\n",
      " 0.57677357 0.57181045 0.5837181  0.56840826]\n",
      "0.5730010674639583\n",
      "\n",
      "\n",
      "0.5668773038441285\n",
      "precision: [0.65932452 0.46153846 0.51547668]\n",
      "recall: [0.54990814 0.00969305 0.80789133]\n",
      "fscore: [0.59966611 0.01898734 0.62937768]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with bigram bag of word\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_bbow, Y_train_bbow, cv=10)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "\n",
    "mnb.fit(X_train_bbow, Y_train_bbow)\n",
    "print(mnb.score(X_test_bbow, Y_test_bbow))\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_bbow, mnb.predict(X_test_bbow))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "#accuracy_score(mnb.predict(X_test_bbow), Y_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "C4B0It9ZC_RW",
    "outputId": "bc355275-2945-49b7-bb14-a470f33c7569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  175.0\n",
      "[0.47667638 0.48785228 0.48420797 0.4749757  0.47400389 0.46622935\n",
      " 0.47570457 0.46950182 0.45686513 0.45929526]\n",
      "0.47253123571942224\n",
      "\n",
      "\n",
      "alpha:  200.0\n",
      "[0.47060253 0.48080661 0.47594752 0.47011662 0.46817298 0.46015549\n",
      " 0.46817298 0.46196841 0.45224787 0.45735115]\n",
      "0.4665542168959235\n",
      "\n",
      "\n",
      "alpha:  225.0\n",
      "[0.46501458 0.47400389 0.47084548 0.4664723  0.46282799 0.45699708\n",
      " 0.46282799 0.4563791  0.44860267 0.45516403]\n",
      "0.4619135118029159\n",
      "\n",
      "\n",
      "alpha:  250.0\n",
      "[0.4606414  0.46987366 0.46525753 0.46379981 0.45845481 0.45359572\n",
      " 0.45894072 0.45224787 0.44738761 0.45176185]\n",
      "0.45819609808860184\n",
      "\n",
      "\n",
      "alpha:  300.0\n",
      "[0.4552964  0.45845481 0.45748299 0.4579689  0.45408163 0.45019436\n",
      " 0.45189504 0.44617254 0.44398542 0.44690158]\n",
      "0.4522433687934469\n",
      "\n",
      "\n",
      "0.6542917324907846\n",
      "precision: [0.74020888 0.73333333 0.59342638]\n",
      "recall: [0.69442743 0.05331179 0.85252264]\n",
      "fscore: [0.71658768 0.09939759 0.69976108]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "# -- multinomialNB with TF-IDF\n",
    "alpha = [175.0, 200.0, 225.0, 250.0, 300.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, X_train_tfidf, Y_train_tfidf, cv=10)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, Y_train_tfidf)\n",
    "print(mnb.score(X_test_tfidf, Y_test_tfidf))\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_tfidf, mnb.predict(X_test_tfidf))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "p0O4c1bVC_RZ"
   },
   "outputs": [],
   "source": [
    "# -- decision tree classifier with BoW\n",
    "dtclassifier=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None)\n",
    "score=cross_val_score(dtclassifier, X_train_bow, Y_train_bow, cv=10)\n",
    "dtclassifier.fit(X_train_bow, Y_train_bow)\n",
    "preddt = dtclassifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_para = {'criterion':['gini','entropy']}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=None), tree_para, cv=10)\n",
    "clf.fit(X_train_bow, Y_train_bow)\n",
    "preddt = dtclassifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "O6sZIkRCC_RZ",
    "outputId": "d7a6c598-e06c-4d6f-d694-17af5d0c26c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6545550289626119\n",
      "precision: [0.68603043 0.55375552 0.66826061]\n",
      "recall: [0.60747091 0.60743134 0.72315653]\n",
      "fscore: [0.64436505 0.57935285 0.69462566]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_bow)\n",
    "print(accuracy)\n",
    "#print(score.mean())\n",
    "# unigram: .69\n",
    "\n",
    "precision, recall, fscore, support = score(Y_test_bbow, preddt)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- decision tree classifier with B-BoW\n",
    "tree_para = {'criterion':['gini','entropy']}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=None), tree_para, cv=10)\n",
    "clf.fit(X_train_bbow, Y_train_bbow)\n",
    "preddt = clf.predict(X_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5092153765139548\n",
      "precision: [0.60194903 0.28851541 0.52857143]\n",
      "recall: [0.49173301 0.33279483 0.59831824]\n",
      "fscore: [0.5412875  0.30907727 0.56128641]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_bbow)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_bbow, preddt)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "K2t4tRpGC_Ra"
   },
   "outputs": [],
   "source": [
    "# -- decision tree classifier with tf-idf\n",
    "tree_para = {'criterion':['gini','entropy']}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(max_depth=None), tree_para, cv=10)\n",
    "clf.fit(X_train_tfidf,Y_train_tfidf)\n",
    "preddt = clf.predict(X_test_tfidf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "6ecSbdERC_Ra",
    "outputId": "cd48ef80-cf60-4b51-d19f-e32eb15f514d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5958399157451291\n",
      "precision: [0.63685272 0.4435591  0.63029525]\n",
      "recall: [0.57991427 0.53957997 0.63518758]\n",
      "fscore: [0.60705128 0.48688047 0.63273196]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(preddt,Y_test_tfidf)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_tfidf, preddt)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SQdF6eqC_Rb",
    "outputId": "f4e9fdda-9853-4141-fb94-3099fc06f3d3"
   },
   "outputs": [],
   "source": [
    "# -- SVM, kernel=linear - BoW\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "C = {'C':[0.01, 0.1, 1, 10, 100]}\n",
    "classifier_linear = GridSearchCV(svm.SVC(kernel='linear'), C, cv=10)\n",
    "\n",
    "#classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(X_train_bow, Y_train_bow)\n",
    "prediction_linear = classifier_linear.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7943654555028963\n",
      "precision: [0.8140263  0.67633588 0.8240621 ]\n",
      "recall: [0.79608083 0.71567044 0.8240621 ]\n",
      "fscore: [0.80495356 0.69544741 0.8240621 ]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(prediction_linear,Y_test_bow)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_bow, prediction_linear)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- SVM, kernel=linear - B-BoW\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(X_train_bbow, Y_train_bbow)\n",
    "prediction_linear = classifier_linear.predict(X_test_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5824117956819379\n",
      "precision: [0.66472727 0.36455982 0.63435264]\n",
      "recall: [0.55970606 0.52180937 0.63065977]\n",
      "fscore: [0.60771277 0.42923588 0.63250081]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "accuracy= accuracy_score(prediction_linear,Y_test_bbow)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_bbow, prediction_linear)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- SVM, kernel=linear - TF-IDF\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(X_train_tfidf, Y_train_tfidf)\n",
    "prediction_linear = classifier_linear.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy= accuracy_score(prediction_linear,Y_test_tfidf)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_tfidf, prediction_linear)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "6k6epXw-C_Rb",
    "outputId": "0e283bf4-085d-40da-d89d-544064f67b7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, multi_class='multinomial')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -- logistic regression with bow \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class=\"multinomial\", C=1)\n",
    "log_reg.fit(X_train_bow, Y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "3SKYyCzjC_Rc",
    "outputId": "6c3fab93-a275-427f-e550-428fecad07e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8022643496577145"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = log_reg.score(X_test_bow, Y_test_bow)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "fVDYoV1DC_Rc",
    "outputId": "afd36e64-3249-4fed-ba18-bc1c7e8de377"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_values</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.596893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.726172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.786203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.802264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.784623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.769879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.771195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_values  Test Accuracy\n",
       "0     0.001       0.596893\n",
       "1     0.010       0.726172\n",
       "2     0.100       0.786203\n",
       "3     1.000       0.802264\n",
       "4    10.000       0.784623\n",
       "5   100.000       0.769879\n",
       "6  1000.000       0.771195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- validation for multinomial log reg \n",
    "C_values = [0.001,0.01, 0.1,1,10,100, 1000]\n",
    "\n",
    "accuracy_values = pd.DataFrame(columns=['C_values', 'Test Accuracy'])\n",
    "\n",
    "for c in C_values:\n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression( C = c, random_state = 0, solver='lbfgs', multi_class='multinomial') # OvR\n",
    "    lr.fit(X_train_bow, Y_train_bow)\n",
    "    accuracy_values = accuracy_values.append({'C_values': c,\n",
    "                                              'Test Accuracy': lr.score(X_test_bow, Y_test_bow)\n",
    "                                             }, ignore_index=True)\n",
    "    pred = lr.predict(X_test_bow)\n",
    "    \n",
    "display(accuracy_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8022643496577145\n",
      "precision: [0.8345093  0.67956656 0.82046453]\n",
      "recall: [0.7966932 0.7092084 0.8454075]\n",
      "fscore: [0.81516291 0.69407115 0.83274928]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "pred = log_reg.predict(X_test_bow)\n",
    "accuracy= accuracy_score(pred, Y_test_bow)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_bow, pred)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, multi_class='multinomial')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -- logistic regression with bbow \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class=\"multinomial\", C=1)\n",
    "log_reg.fit(X_train_bbow, Y_train_bbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000526592943655"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = log_reg.score(X_test_bbow, Y_test_bbow)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_values</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.455503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.526330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.589258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.599789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.593997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.585835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_values  Test Accuracy\n",
       "0     0.001       0.455503\n",
       "1     0.010       0.526330\n",
       "2     0.100       0.589258\n",
       "3     1.000       0.600053\n",
       "4    10.000       0.599789\n",
       "5   100.000       0.593997\n",
       "6  1000.000       0.585835"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- validation for multinomial log reg \n",
    "C_values = [0.001,0.01, 0.1,1,10,100, 1000]\n",
    "\n",
    "accuracy_values = pd.DataFrame(columns=['C_values', 'Test Accuracy'])\n",
    "\n",
    "for c in C_values:\n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression( C = c, random_state = 0, solver='lbfgs', multi_class='multinomial')\n",
    "    lr.fit(X_train_bbow, Y_train_bbow)\n",
    "    accuracy_values = accuracy_values.append({'C_values': c,\n",
    "                                              'Test Accuracy': lr.score(X_test_bbow, Y_test_bbow)\n",
    "                                             }, ignore_index=True)\n",
    "    pred = lr.predict(X_test_bbow)\n",
    "    \n",
    "display(accuracy_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000526592943655\n",
      "precision: [0.66689751 0.43625498 0.59233261]\n",
      "recall: [0.58971219 0.35379645 0.70957309]\n",
      "fscore: [0.62593435 0.39072257 0.64567393]\n",
      "support: [1633  619 1546]\n"
     ]
    }
   ],
   "source": [
    "pred = log_reg.predict(X_test_bbow)\n",
    "accuracy= accuracy_score(pred, Y_test_bbow)\n",
    "print(accuracy)\n",
    "precision, recall, fscore, support = score(Y_test_bbow, pred)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "covid19-tweets-sentiment-analysis-nlp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 3889.575075,
   "end_time": "2021-02-14T13:29:29.031663",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-14T12:24:39.456588",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
